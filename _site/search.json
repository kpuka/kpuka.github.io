[
  {
    "objectID": "resources/r_intro.html",
    "href": "resources/r_intro.html",
    "title": "Introduction to R",
    "section": "",
    "text": "Topic: Introduction to data wrangling and data management with R.\nR is a powerful programming language and software environment widely used for statistical computing, data analysis, and graphical visualization.",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#functions-and-packages",
    "href": "resources/r_intro.html#functions-and-packages",
    "title": "Introduction to R",
    "section": "Functions and Packages",
    "text": "Functions and Packages\n\nFunctions essential building blocks that enable you to perform specific tasks efficiently. They are like a set of instructions designed to carry out various operations, saving you from having to write complex code each time you want to perform a common task.\n\nIn R, a function is a named block of code that takes inputs (arguments) and returns outputs (results).\nFor example, mean() calculates the mean of a set of numbers, so you don’t have to write the formula to calculate the mean each time\n\nPackages, just like smartphone apps, are created by individuals/groups and extend the functionality of R by providing a a collection of functions\nTo use packages:\n\nFirst time only: install the package using install.packages(\"package_name\")\nEach time you open R: load the package using library(package_name)\n\nSometimes, different packages may use the same function name\n\nTo specify the package and function name: package_name::function_name()\n\nR’s vast collection of packages, combined with the ability to create your own functions, make it a powerful tool",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#basic-operations-and-functions",
    "href": "resources/r_intro.html#basic-operations-and-functions",
    "title": "Introduction to R",
    "section": "Basic Operations and Functions",
    "text": "Basic Operations and Functions\n\n\n\n\n\n\n\nOperator\nDescription\n\n\n\n\n$\nUsed to access/refer to specific elements/variables within a data frame or list\n\n\n&lt;-\n“save as”. Arrow pointing to the left - the object on the left will be defined/crehtated based on the instructions on the right\n\n\n|&gt;  %&gt;%\n“and then”, will take the output from the first function and use it as the first input of the second function. For example:  function(data, arguments) is the same as  data |&gt; function(arguments)\n\n\n( )\nUsed primarily to specify the arguments of a function\n\n\nc( )\nIs a function allowing you to combine multiple elements into a single object. It stands for ‘combine’ or ‘concatenate’\n\n\n|\nOr\n\n\n&\nAnd",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#resources-and-help-files",
    "href": "resources/r_intro.html#resources-and-help-files",
    "title": "Introduction to R",
    "section": "Resources and Help Files",
    "text": "Resources and Help Files\n\nHelpful books include R for Data Science and Advanced R\nMany packages also have websites, such as https://www.tidyverse.org/packages/\n\nGoogle, and more recently chatGPT, will be your best friend\n\nR has built-in help files that provide syntax, arguments, usage, and examples\n\nTo access a help file, use ? followed by the function name (e.g. ?mean)\n\n\n\n?mean",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#import-data-into-r",
    "href": "resources/r_intro.html#import-data-into-r",
    "title": "Introduction to R",
    "section": "Import Data into R",
    "text": "Import Data into R\n\nPlace the data file in the same folder as the “.Rproj” file (the file that was created when you created an R Project)\nIn R, use read.csv() opens CSV files; specify the file location/name\n\n\nnhis2018 &lt;- read.csv(\"nhis2018_SampleAdult.csv\")\n\n  # read.csv() reads the file\n  # \"&lt;-\" is used to assign/save the data to an object named 'nhis2018'\n\n\nFiles located in other folders\nIf the data file is located in a different folder, the location needs to be specified. Because we created an R Project, R will start by looking at the folder that contains the “.Rproj” file (the file that was created when you created an R Project).\n\nIf the data was in a folder called ‘data’ within the folder containing “.Rproj”, the code is: nhis2018 &lt;- read.csv(\"data/nhis2018_SampleAdult.csv\")\nIf the data was in a folder that is ‘a level above’ the folder containing “.Rproj”, the code is: nhis2018 &lt;- read.csv(\"../nhis2018_SampleAdult.csv\")\n\n\n\nLoad other file types\n\nR: nhis2018 &lt;- readRDS(\"data_name.R\")\nExcel: nhis2018 &lt;- read_excel(\"data_name.xlsx\") (readxl package)",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#exporting-data-from-r",
    "href": "resources/r_intro.html#exporting-data-from-r",
    "title": "Introduction to R",
    "section": "Exporting Data from R",
    "text": "Exporting Data from R\nUse saveRDS() to save as an R object\n\nSpecify the object to save, then the location and name of the file to be saved\n\n\nsaveRDS(nhis2018, \"updated_nhis2018.R\")\n\n\nUse write.csv() to save as a CSV file\n\nwrite.csv(nhis2018, \"updated_nhis2018.csv\")",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#labeling-variables",
    "href": "resources/r_intro.html#labeling-variables",
    "title": "Introduction to R",
    "section": "Labeling Variables",
    "text": "Labeling Variables\n\nUse factor() to create and label factors\n\nImportantly, the first level listed will be the ‘reference’ level used in statistical models\nAlternatively, use relevel() to change the reference level\n\nConsider creating a new variable for the labeled version, e.g. “variable_name.factor”\n\nThis gives two versions of the variable - one coded numerically, the other by labels\n\n\n\n\n\n# Create factor for 'sex', reference level=Female\nnhis2018$SEX.factor &lt;- factor(nhis2018$SEX,\n                              levels=c(2, 1),\n                              labels =c(\"Women\", \n                                        \"Men\"))\n\n\n\n# Change reference level of an exist factor\nnhis2018$SEX.factor &lt;- relevel(nhis2018$SEX.factor, \n                               ref = \"Men\")    \n\n\n\n\n\n\n\n\n\n\nResult:\n\n\nID\nSEX\nSEX.factor\n\n\n\n\n1\n2\nWomen\n\n\n2\n2\nWomen\n\n\n3\n1\nMen\n\n\n4\n2\nWomen\n\n\n5\n1\nMen\n\n\n6\n1\nMen",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#clean-data-frame-overall",
    "href": "resources/r_intro.html#clean-data-frame-overall",
    "title": "Introduction to R",
    "section": "Clean data frame (overall)",
    "text": "Clean data frame (overall)\nThe janitor package provides several functions for cleaning and tidying data.\n\nclean_names() converts column names to a consistent format (easier to work with)\nremove_empty() removes rows and/or columns that contain only missing values\n\n\n\n\ninstall.packages(\"janitor\")\nlibrary(janitor)        \n\nnhis2018 &lt;- nhis2018 |&gt; \n  clean_names() |&gt; \n  remove_empty (\"cols\")\n\n\n# check variable names \nnames(nhis2018)\n\n\nOriginal variable names:\n\n\n [1] \"ID\"         \"REGION\"     \"AGE_P\"      \"SEX\"        \"R_MARITL\"  \n [6] \"AHEIGHT\"    \"AWEIGHTP\"   \"ASISLEEP\"   \"HYPEV\"      \"CHLEV\"     \n[11] \"DIBEV1\"     \"AHSTATYR\"   \"SMKSTAT2\"   \"ASISAD\"     \"ASINERV\"   \n[16] \"ASIRSTLS\"   \"ASIHOPLS\"   \"ASIEFFRT\"   \"ASIWTHLS\"   \"SEX.factor\"\n\n\nNew variable names:\n\n\n [1] \"id\"         \"region\"     \"age_p\"      \"sex\"        \"r_maritl\"  \n [6] \"aheight\"    \"aweightp\"   \"asisleep\"   \"hypev\"      \"chlev\"     \n[11] \"dibev1\"     \"ahstatyr\"   \"smkstat2\"   \"asisad\"     \"asinerv\"   \n[16] \"asirstls\"   \"asihopls\"   \"asieffrt\"   \"asiwthls\"   \"sex_factor\"",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#tidyverse-package",
    "href": "resources/r_intro.html#tidyverse-package",
    "title": "Introduction to R",
    "section": "Tidyverse Package",
    "text": "Tidyverse Package\n\nIs a collection of packages with tools for data manipulation, visualization, and modeling\n\n\ninstall.packages(\"tidyverse\") # Install the package (first time only)\nlibrary(tidyverse)            # Load the package (each time you load R)\n\nContains several functions that will be used throughout the workshop, including:\n\nrename() change the name of a column (aka variables)\nfilter() keeps or discards rows (aka observations)\nselect() keeps or discards columns (aka variables)\narrange()sorts data set by certain variable(s)\ncount() tallies data set by certain variable(s)\nmutate()creates new variables\nsummarize() aggregates data\n\nTypically, the first argument in these functions is the data frame, followed by the operation you want to perform",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#rename-variables",
    "href": "resources/r_intro.html#rename-variables",
    "title": "Introduction to R",
    "section": "Rename Variables",
    "text": "Rename Variables\n\nUse rename() to change the names of variables\nFirst argument is the data frame, followed by a list of ‘new_name = old_name’ statements\n\n\nnhis2018 &lt;- nhis2018 |&gt;\n  rename(age = age_p,\n         marital = r_maritl,\n         height_in = aheight,\n         weight_lb = aweightp,\n         sleep_hrs = asisleep,\n         health_chage = ahstatyr,\n         smoking = smkstat2)\n\n# Check\nnames(nhis2018)\n\n [1] \"id\"           \"region\"       \"age\"          \"sex\"          \"marital\"     \n [6] \"height_in\"    \"weight_lb\"    \"sleep_hrs\"    \"hypev\"        \"chlev\"       \n[11] \"dibev1\"       \"health_chage\" \"smoking\"      \"asisad\"       \"asinerv\"     \n[16] \"asirstls\"     \"asihopls\"     \"asieffrt\"     \"asiwthls\"     \"sex_factor\"",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#removekeep-observations",
    "href": "resources/r_intro.html#removekeep-observations",
    "title": "Introduction to R",
    "section": "Remove/Keep observations",
    "text": "Remove/Keep observations\nUse filter() to specify the rows (aka observations) to keep\nSpecify the data frame, followed by the conditions you want to keep:\n\n\n\n# Keep only rows where region &gt; 1\nnhis2018 &lt;- nhis2018 |&gt;\n  filter(region &gt;1)\n\n# check\ncount(nhis2018, region)  \n\n\n\n\nOld frequncy:\n\n\n\n\n\nregion\nn\n\n\n\n\n1\n72\n\n\n2\n122\n\n\n3\n190\n\n\n4\n116\n\n\n\n\n\n\n\n\nNew frequncy:\n\n\n\n\n\nregion\nn\n\n\n\n\n2\n122\n\n\n3\n190\n\n\n4\n116\n\n\n\n\n\n\n\n\nOther examples, using different operators:\n\n\n\n\n\n\n\nCode\nDescription of rows to keep\n\n\n\n\nfilter(region == 1 & sex == 1)\nregion equals 1 AND sex equals 1\n\n\nfilter(region == 1 | marital &gt;3)\nregion equals 1 OR marital greater than 3\n\n\nfilter(marital %in% c(1,3))\nmarital is equal to 1 or 3\n\n\nfilter(is.na(marital))\nmarital is missing\n\n\nfilter(marital != 3)\nmarital does not equal 3\n\n\nfilter(!is.na(marital))\nmarital is not missing",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#removekeep-variables",
    "href": "resources/r_intro.html#removekeep-variables",
    "title": "Introduction to R",
    "section": "Remove/Keep variables",
    "text": "Remove/Keep variables\nUse select() to specify the columns (aka variables) to keep\nSpecify the data frame, followed by the conditions you want to keep\n\n# Remove the 'sex' column (given the prefix '-')\nnhis2018 &lt;- nhis2018 |&gt;\n  select(-sex)  \n\n# Check\nhead(nhis2018, 10)\n\n\n\n\n\n\n\n\n\n\nid\nregion\nage\nmarital\nheight_in\nweight_lb\nsleep_hrs\nhypev\nchlev\ndibev1\nhealth_chage\nsmoking\nasisad\nasinerv\nasirstls\nasihopls\nasieffrt\nasiwthls\nsex_factor\n\n\n\n\n1\n3\n66\n1\n66\n180\n8\n2\n2\n2\n3\n4\n5\n5\n5\n5\n5\n5\nWomen\n\n\n2\n3\n18\n7\n63\n123\n7\n2\n2\n2\n3\n4\n1\n5\n5\n5\n5\n5\nWomen\n\n\n4\n4\n25\n7\n63\n110\n7\n2\n2\n2\n3\n4\n5\n5\n5\n5\n5\n5\nWomen\n\n\n5\n4\n61\n7\n72\n250\n6\n1\n1\n2\n3\n3\n5\n5\n5\n5\n5\n5\nMen\n\n\n7\n2\n22\n7\n65\n200\n7\n2\n2\n2\n3\n4\n5\n3\n4\n5\n5\n5\nWomen\n\n\n8\n3\n46\n1\n61\n150\n6\n2\n2\n2\n3\n4\n5\n5\n5\n5\n5\n5\nWomen\n\n\n9\n2\n64\n1\n67\n188\n8\n2\n2\n2\n1\n4\n4\n5\n5\n5\n5\n5\nWomen\n\n\n11\n2\n36\n1\n67\n115\n8\n2\n2\n2\n3\n4\n5\n4\n4\n5\n5\n5\nWomen\n\n\n12\n2\n38\n1\n65\n997\n8\n2\n2\n2\n3\n4\n5\n5\n5\n5\n5\n5\nWomen\n\n\n13\n3\n66\n1\n59\n120\n6\n2\n2\n2\n3\n4\n5\n5\n4\n5\n5\n5\nWomen\n\n\n\n\n\n\n\n\n\nOther examples, using different operators\n\n\n\n\n\n\n\n\nCode\nDescription of columns to keep\n\n\n\n\nselect(age, marital, sex)\nthe variables listed (in the order listed)\n\n\nselect(age:sleep_hrs)\nthe variables from age to sleep_hrs\n\n\nselect(contains(\"sleep\"))\nthe variables that contain “sleep”\n\n\nselect(starts_with(\"slee\"))\nthe variables that start with “slee”\n\n\nselect(where(is.numeric))\nthe variables which are numeric",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#move-columns",
    "href": "resources/r_intro.html#move-columns",
    "title": "Introduction to R",
    "section": "Move columns",
    "text": "Move columns\nUse relocate() to move columns within a data frame\nSpecify the data frame, followed by the new order of the columns\n\n# move the variable 'sex_factor' to appear before the 'age' variable \nnhis2018 &lt;- nhis2018 |&gt; \n  relocate(sex_factor, .before = age)\n\n# Check \nhead(nhis2018, 7)\n\n\n\n\n\n\n\n\n\n\nid\nregion\nsex_factor\nage\nmarital\nheight_in\nweight_lb\nsleep_hrs\nhypev\nchlev\ndibev1\nhealth_chage\nsmoking\nasisad\nasinerv\nasirstls\nasihopls\nasieffrt\nasiwthls\n\n\n\n\n1\n3\nWomen\n66\n1\n66\n180\n8\n2\n2\n2\n3\n4\n5\n5\n5\n5\n5\n5\n\n\n2\n3\nWomen\n18\n7\n63\n123\n7\n2\n2\n2\n3\n4\n1\n5\n5\n5\n5\n5\n\n\n4\n4\nWomen\n25\n7\n63\n110\n7\n2\n2\n2\n3\n4\n5\n5\n5\n5\n5\n5\n\n\n5\n4\nMen\n61\n7\n72\n250\n6\n1\n1\n2\n3\n3\n5\n5\n5\n5\n5\n5\n\n\n7\n2\nWomen\n22\n7\n65\n200\n7\n2\n2\n2\n3\n4\n5\n3\n4\n5\n5\n5\n\n\n8\n3\nWomen\n46\n1\n61\n150\n6\n2\n2\n2\n3\n4\n5\n5\n5\n5\n5\n5\n\n\n9\n2\nWomen\n64\n1\n67\n188\n8\n2\n2\n2\n1\n4\n4\n5\n5\n5\n5\n5\n\n\n11\n2\nWomen\n36\n1\n67\n115\n8\n2\n2\n2\n3\n4\n5\n4\n4\n5\n5\n5\n\n\n12\n2\nWomen\n38\n1\n65\n997\n8\n2\n2\n2\n3\n4\n5\n5\n5\n5\n5\n5\n\n\n13\n3\nWomen\n66\n1\n59\n120\n6\n2\n2\n2\n3\n4\n5\n5\n4\n5\n5\n5",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#simple-recoding",
    "href": "resources/r_intro.html#simple-recoding",
    "title": "Introduction to R",
    "section": "Simple Recoding",
    "text": "Simple Recoding\n\nUsing ifelse()\nLets calculate BMI\n\nFirst, use ifelse() to remove the values that specify the different types of missing data (see codebook)\nTemplate of ifelse(): ifelse(condition, value_if_true, value_if_false)\n\n\n\n\nnhis2018 &lt;- nhis2018 |&gt;\n  mutate(height_in = ifelse (height_in %in% c(96, 97, 98, 99), NA, height_in),\n         weight_lb = ifelse(weight_lb &gt;=996, NA, weight_lb),\n         bmi = weight_lb / height_in^2 * 703)  # this is the formula for BMI\n\n\n# Check\nnhis2018 |&gt;\n  select (id, height_in, weight_lb, bmi) |&gt;\n  head(7)  # The number indicates how many rows/observations to print\n\n# To check, you can alternatively, click on the name of the data set \n# in the 'Environment' window to see the entire data set\n\n\n\n\n\n\n\n\n\n\nResult:\n\n\nid\nheight_in\nweight_lb\nbmi\n\n\n\n\n1\n66\n180\n29.04959\n\n\n2\n63\n123\n21.78609\n\n\n4\n63\n110\n19.48350\n\n\n5\n72\n250\n33.90239\n\n\n7\n65\n200\n33.27811\n\n\n8\n61\n150\n28.33916\n\n\n9\n67\n188\n29.44175\n\n\n\n\n\n\n\n\n\n\n\nCreate/recode categorical variables\nUse cut() to categorize continuous variables\n\nSpecify the lowest value, the cut off points, and the highest value\nSubsequently, specify the labels for each category\n\nUse case_match() to manually recode any variable\n\nImportant: The order of statement matters for case_match() - the new variable will have the value associated with the first condition that is met\n\n\n\n\nnhis2018 &lt;- nhis2018 |&gt;\n mutate(bmi_category = cut(bmi, \n                           breaks=c(-Inf, 18.5, 25, 30, Inf), \n                           labels=c(\"Underweight\", \n                                    \"Healthy weight\", \n                                    \"Overweight\", \n                                    \"Obese\")),\n        \n        bmi_binary = case_match(bmi_category, \n                          c(\"Underweight\", \"Healthy weight\") ~ \"Low\",\n                          \"Overweight\" ~ \"High\",\n                          \"Obese\" ~ \"High\"))  \n\n# Check\nnhis2018 |&gt;\n  select (id, bmi, bmi_category, bmi_binary) |&gt;\n  head(12) # The number indicates how many rows/observations to print\n\n# To check, you can alternatively, click on the name of the data set \n# in the 'Environment' window to see the entire data set\n\n\n\n\n\n\n\n\n\n\nResult:\n\n\nid\nbmi\nbmi_category\nbmi_binary\n\n\n\n\n1\n29.04959\nOverweight\nHigh\n\n\n2\n21.78609\nHealthy weight\nLow\n\n\n4\n19.48350\nHealthy weight\nLow\n\n\n5\n33.90239\nObese\nHigh\n\n\n7\n33.27811\nObese\nHigh\n\n\n8\n28.33916\nOverweight\nHigh\n\n\n9\n29.44175\nOverweight\nHigh\n\n\n11\n18.00958\nUnderweight\nLow\n\n\n12\nNA\nNA\nNA\n\n\n13\n24.23442\nHealthy weight\nLow\n\n\n14\n29.61973\nOverweight\nHigh\n\n\n15\n33.44723\nObese\nHigh",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#complex-recoding",
    "href": "resources/r_intro.html#complex-recoding",
    "title": "Introduction to R",
    "section": "Complex Recoding",
    "text": "Complex Recoding\nUse case_when() to recode using multiple conditions\n\nImportant: The order of statement matters for case_when()- the new variable will have the value associated with the first condition that is met\n\n\n\nnhis2018 &lt;- nhis2018 |&gt;\n  mutate(bmi_cateory2 = case_when (bmi &lt; 18.5 ~ \"Underweight\",\n                                  bmi &lt;25 ~ \"Healthy weight\",\n                                  bmi &lt;30 ~ \"Over weight\",\n                                  bmi&gt;=30 ~ \"Obese\",\n                                  .default  = NA),\n    \n    bmi_sex = case_when (bmi &gt; 18 & bmi &lt;25 & sex_factor == \"Men\" ~ \"Healthy Weight Men\",\n                        bmi &gt; 18 & bmi &lt;25 & sex_factor == \"Women\" ~ \"Healthy Weight Women\",\n                        sex_factor == \"Men\" & !is.na(bmi) ~ \"Not-healthy weight Men\",\n                        sex_factor == \"Women\" & !is.na(bmi) ~ \"Not-healthy weight Women\"))\n\n\n# Check by viewing the data\n# Alternative, can use frequency tables to check:\ncount(nhis2018, sex_factor, bmi_cateory2, bmi_sex)\n\n\n\n\n\n\n\n\n\n\n\n\nsex_factor\nbmi_cateory2\nbmi_sex\nn\n\n\n\n\nMen\nHealthy weight\nHealthy Weight Men\n46\n\n\nMen\nObese\nNot-healthy weight Men\n55\n\n\nMen\nOver weight\nNot-healthy weight Men\n81\n\n\nMen\nNA\nNA\n17\n\n\nWomen\nHealthy weight\nHealthy Weight Women\n67\n\n\nWomen\nObese\nNot-healthy weight Women\n62\n\n\nWomen\nOver weight\nNot-healthy weight Women\n66\n\n\nWomen\nUnderweight\nHealthy Weight Women\n4\n\n\nWomen\nUnderweight\nNot-healthy weight Women\n4\n\n\nWomen\nNA\nNA\n26\n\n\n\n\n\n\n\n\n This table has a row for each unique combination of the variables, and an additional column (n) which indicates the count of observations for each unique combination of the variables.\nFor example, the first row indicates that there are 46 individuals whose ‘sex_factor’ = Men, AND ‘bmi_category2’ = Health weight, AND ‘bmi_sex’ = Health Weight Men.\nUse this data to check the count for each combination, and check to ensure that all of the combinations listed align with what you would expect.",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#working-with-strings",
    "href": "resources/r_intro.html#working-with-strings",
    "title": "Introduction to R",
    "section": "Working with Strings",
    "text": "Working with Strings\nThe stringr package (part of tidyverse) provides several useful functions to work with strings:\n\nstr_detect() checks if a pattern is present in a string.\nstr_replace() replaces a pattern in a string with another string.\n\n\nnhis2018 &lt;- nhis2018 |&gt;\n  mutate(\n    # Replace hyphens (-) with comma (,) \n    marital_new = str_replace(marital, \" - \", \", \"),\n\n    # Recode based on a given pattern\n    is_married = ifelse(str_detect(marital, \"marri\"), \"Yes\", \"No\"))\n\n\n# Check \ncount(nhis2018, marital, marital_new, is_married)\n\n\n\n\n\n\n\n\n\n\nmarital\nmarital_new\nis_married\nn\n\n\n\n\nMarried - spouse in household\nMarried, spouse in household\nNo\n180\n\n\nMarried - spouse not in household\nMarried, spouse not in household\nNo\n9\n\n\nWidowed\nWidowed\nNo\n53\n\n\nDivorced\nDivorced\nNo\n55\n\n\nSeparated\nSeparated\nNo\n10\n\n\nNever married\nNever married\nYes\n91\n\n\nLiving with partner\nLiving with partner\nNo\n28\n\n\nUnknown marital status\nUnknown marital status\nNo\n2",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#long-to-wide",
    "href": "resources/r_intro.html#long-to-wide",
    "title": "Introduction to R",
    "section": "Long to Wide",
    "text": "Long to Wide\nUse pivot_wider() to transition from long to wide\n\nwide_data &lt;- long_data %&gt;%\n pivot_wider(\n   names_from = \"time\",                # the repeating event variable\n   values_from = c(\"QOL\",\"Anx\",\"Dep\")) # variable with repeated observations\n\n\n\nlong_data:\n\n\n\n\n\nID\nSex\ntime\nQOL\nAnx\nDep\n\n\n\n\n1\nM\n1\n63\n33\n59\n\n\n1\nM\n2\n74\n32\n50\n\n\n2\nM\n1\n75\n35\n53\n\n\n2\nF\n2\n76\n34\n48\n\n\n3\nM\n1\n54\n44\n51\n\n\n3\nF\n2\n76\n29\n45\n\n\n4\nF\n1\n77\n39\n47\n\n\n4\nF\n2\n58\n42\n47\n\n\n5\nM\n1\n78\n36\n48\n\n\n5\nM\n2\n84\n32\n59\n\n\n\n\n\n\n\n\nwide_data:\n\n\n\n\n\nID\nSex\nQOL_1\nQOL_2\nAnx_1\nAnx_2\nDep_1\nDep_2\n\n\n\n\n1\nM\n63\n74\n33\n32\n59\n50\n\n\n2\nM\n75\nNA\n35\nNA\n53\nNA\n\n\n2\nF\nNA\n76\nNA\n34\nNA\n48\n\n\n3\nM\n54\nNA\n44\nNA\n51\nNA\n\n\n3\nF\nNA\n76\nNA\n29\nNA\n45\n\n\n4\nF\n77\n58\n39\n42\n47\n47\n\n\n5\nM\n78\n84\n36\n32\n48\n59",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#wide-to-long",
    "href": "resources/r_intro.html#wide-to-long",
    "title": "Introduction to R",
    "section": "Wide to Long",
    "text": "Wide to Long\nUse pivot_longer() to transition from wide to long\nIf needed, it is easiest to rename variables to utilize a unique separator (e.g., _ or __)\n\nlong_data &lt;- wide_data %&gt;%\n  pivot_longer(\n    cols = QOL_1:Dep_2,             # variables to be transposed\n    names_to = c(\".value\", \"time\"), # specify new column names\n    names_sep = \"_\" )               # where the column name is broken up\n\n\n\nwide_data:\n\n\n\n\n\nID\nSex\nQOL_1\nQOL_2\nAnx_1\nAnx_2\nDep_1\nDep_2\n\n\n\n\n1\nM\n63\n74\n33\n32\n59\n50\n\n\n2\nM\n75\nNA\n35\nNA\n53\nNA\n\n\n2\nF\nNA\n76\nNA\n34\nNA\n48\n\n\n3\nM\n54\nNA\n44\nNA\n51\nNA\n\n\n3\nF\nNA\n76\nNA\n29\nNA\n45\n\n\n4\nF\n77\n58\n39\n42\n47\n47\n\n\n5\nM\n78\n84\n36\n32\n48\n59\n\n\n\n\n\n\n\n\nlong_data:\n\n\n\n\n\nID\nSex\ntime\nQOL\nAnx\nDep\n\n\n\n\n1\nM\n1\n63\n33\n59\n\n\n1\nM\n2\n74\n32\n50\n\n\n2\nM\n1\n75\n35\n53\n\n\n2\nM\n2\nNA\nNA\nNA\n\n\n2\nF\n1\nNA\nNA\nNA\n\n\n2\nF\n2\n76\n34\n48\n\n\n3\nM\n1\n54\n44\n51\n\n\n3\nM\n2\nNA\nNA\nNA\n\n\n3\nF\n1\nNA\nNA\nNA\n\n\n3\nF\n2\n76\n29\n45\n\n\n4\nF\n1\n77\n39\n47\n\n\n4\nF\n2\n58\n42\n47\n\n\n5\nM\n1\n78\n36\n48\n\n\n5\nM\n2\n84\n32\n59",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#same-participants-different-variables",
    "href": "resources/r_intro.html#same-participants-different-variables",
    "title": "Introduction to R",
    "section": "Same participants, different variables:",
    "text": "Same participants, different variables:\n\nfull_join() keeps all observations\ninner_join() keeps all observations that are in the first AND second data\nleft_join() keeps all observations in the first data\nright_join() keeps all observations in the second data\n\nTo combine &gt;2 data frames, run the function multiple times\n\nnew_data &lt;- full_join (data_1, data_2, by=\"ID\")",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/r_intro.html#different-participants-same-variables",
    "href": "resources/r_intro.html#different-participants-same-variables",
    "title": "Introduction to R",
    "section": "Different participants, same variables",
    "text": "Different participants, same variables\n\nColumns with the exact same names will be merged\nOthers will be retained and include missing data where appropriate\n\n\nnew_data &lt;- bind_rows (data_1, data_2)",
    "crumbs": [
      "R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html",
    "href": "resources/quarto_intro.html",
    "title": "Introduction to Quarto",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. Quarto is a multi-language program, supporting multiple types of inputs languages (e.g., R, python, HTML), input software (e.g., RStudio, VScode, plain text), and outputs/documents (e.g., HTML document, presentation slides, PDFs, word documents).\nQuarto is the next generation of R Markdown, and is able to render most existing R Markdown (Rmd) files without modification. Most of the information presented below will work both in Quarto and Markdown. Syntax that is common to both will be noted as ‘Syntax (Input)’, whereas syntax specific to Quarto will be noted as ‘Quarto Syntax (Input)’.\nThis introduction will focus on creating an HTML file using the RStudio environment.",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#heading-2",
    "href": "resources/quarto_intro.html#heading-2",
    "title": "Introduction to Quarto",
    "section": "Heading 2",
    "text": "Heading 2\n\nHeading 3\n Bold text like this or this\nItalicize text like this or this\n Clickable link: https://google.com\nHyperlink\n\n\nBullet point (nordered lists)\nHyphen, followed by ‘tab’\n\n\nOrdered list\nNumber, period, then ‘tab’\n\n\n\n\n\n\nManual\nTable\n\n\n\n\nVariable 1\n11\n21\n\n\nVariable 2\n12\n22\n\n\nVariable 3\n12\n23",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#columns",
    "href": "resources/quarto_intro.html#columns",
    "title": "Introduction to Quarto",
    "section": "5.1 Columns",
    "text": "5.1 Columns\nTo create and work with columns, use ::: or ::::. Like brackets, these are used to indicate the start and end the content to be placed in columns.\nHere’s an example:\n\n\n\nQuarto Syntax (Input)\n:::: columns\n::: {.column}\nContent of column 1\n:::\n\n::: {.column}\nContent of column 2\n:::\n::::\n\n\n\nExplanation\n:::: columns indicates that what comes next should be presented in columns.\n::: {.column} indicates that what comes next are the content of column 1.\n::: indicates the end of the content of column 1\nThe very last :::: indicates the end of the columns.\n\n\n\nAdditional arguments can be added within the curly brackets:\n\n::: {.column width=\"40%\"} indicates that the column should take up 40% of the screen\n::: {.column font-size: \"60%\"} indicates that the content within the column should be a different size font\n::: {.column .fragment} (for presentations) indicates that the content of the column should appear after a click\nMultiple arguments can be integrated together: ::: {.column width=\"40%; font-size: 60%;\" .fragment}\n\nMost of this document is created using columns, such that the code is specified but not run in column 1, and in column 2 the code is repeated and implemented.",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#layouts",
    "href": "resources/quarto_intro.html#layouts",
    "title": "Introduction to Quarto",
    "section": "5.2 Layouts",
    "text": "5.2 Layouts\nSimilar to columns, custom ‘layouts’ can also be used to create columns or a more complex organization of the output.\nTo create two columns, each taking up 50% of the page, you can use either one of the following:\n\n\n\n\n\n\nSpecify number of equally-sized columns\n:::: {layout-ncol=2}\n::: {#first-column}\nContent of column 1\n:::\n    \n::: {#Second-column}\nContent of column 2\n:::\n::::\n\n\n \n\n\nManually specify proportion of each column\n:::: {layout=\"[50, 50]\"}\n::: {#first-column}\nContent of column 1\n:::\n    \n::: {#Second-column}\nContent of column 2\n:::\n::::\n\n\n\nThe id attributes (#first-column and #second-column) are optional, but aid readability.\nLayouts are powerful because they can create complex organizations; for example:\n\n\n\n\n\n\n:::: {layout=\"[[45, -10, 45], [100]]\"}\n:::{#Output1}\nContent 1\n:::\n\n:::{#Output2}\nContent 2\n:::\n        \n:::{#Output3}\nContent 2\n:::\n::::\n\n\nThis example will organize the three pieces of output in the following ways:\n\nOutput1 will show in the first row and take up 45% of the page width\nOutput2 will show in the first row and take up 45% of the page width\nThe -10 defined the amount of empty space between Output1 and Output2\nOutput3 will show in the second row, and take up 100% of the page width\n\n\n\n\nNotably, these layout options can also be integrated within the code chunk. For example:\n\n#| layout-ncol: 2\n\n#| layout: [50, 50]",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#callout-blocks",
    "href": "resources/quarto_intro.html#callout-blocks",
    "title": "Introduction to Quarto",
    "section": "5.3 Callout Blocks",
    "text": "5.3 Callout Blocks\nCallouts are used to draw extra attention to certain concepts, or to more clearly indicate that certain content is supplemental or applicable to only some scenarios.\nCallouts start with ::: {.callout-note}, then there’s the content, and it ends with :::.\nThere are five types of callouts: note, warning, important, tip, and caution.\n\n\n\nQuarto Syntax (Input)\n\n:::{.callout-note}\nThis is a callout block of the type \"note\".\n:::\n\n:::{.callout-caution collapse=\"true\"}\nCallouts can be collapsible. \n:::\n\n:::{.callout-important}\n# My heading\nThe first heading used within the callout \nis used as the callout heading.\n:::\n\n:::{.callout-tip icon=false}\nThe icon can also be hidden, like this. \n:::\n\n\n:::{.callout}\nThis is a simpler callout, without \nspecifying the \"type\". \n:::\n\n\n\nFormatted Output\n\n\n\n\n\n\nNote\n\n\n\nThis is a callout block of the type “note”.\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\nCallouts can be collapsible.\n\n\n\n\n\n\n\n\n\n\nMy heading\n\n\n\nThe first heading used within the callout is used as the callout heading.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe icon can also be hidden, like this.\n\n\n\n\n\n\n\n\n\nThis is a simpler callout, without specifying the “type”.\n\n\n\n\n\n\n\nAn alternative method of collapsing sections is presented in Section 8.5.2 and uses HTML code.",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#tabsets",
    "href": "resources/quarto_intro.html#tabsets",
    "title": "Introduction to Quarto",
    "section": "5.4 Tabsets",
    "text": "5.4 Tabsets\nAnother way to organize a report is to present information in different tabs. \nSimilarly, as before, this is coded using ::: to denote the start and end of the information to be presented in tabs.\nLevel 3 headings (specified using ###) are used as the tab title and denote the start of each new tab. \nHere a simple example:\n\n\n\nSyntax (Input)\n::: {.panel-tabset}\n\n### Panel 1 Title\nContent of panel 1\n\n### Panel 2 Title\nContent of panel 2\n\n:::\n\n\n\nFormatted Output\n\nPanel 1 TitlePanel 2 Title\n\n\nContent of panel 1\n\n\nContent of panel 2",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#execution-options",
    "href": "resources/quarto_intro.html#execution-options",
    "title": "Introduction to Quarto",
    "section": "6.1 Execution Options",
    "text": "6.1 Execution Options\nThere are a variety of options for how to handle the code and its output, called ‘execution options’. These options are specified at the start of the code chunk, and begin with #|\nFor example, to output just the code chunk, without executing the code and to ignore any warnings:\n\n```{r}\n#| eval: false\n#| warning: false\n1 + 1\n```\n\nOther execution options include:\n\neval: true indicates that the code chunk should be ‘evaluated’ or ‘run’\necho: true indicates the code chunk should be ‘echoed’ or shown along in the output\nwarning: false indicates that any warning messags should not be shown in the output\noutput: asis indicates that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown\ninclude: false is a catch all, indicating neither the code chunk nor results should be shown in the output\nfile: \"Name of R file.R\" can be used to import, display, and run the code that is in a separate file called “Name of R file.R”. Useful if you have custom functinos saved in a separate R script, and want to show the function code in your final document.\ncode-fold: true indicates that the code chunk is shown, but presented in a collapseble format\n\n#| code-summary: \"Title of folding code\" indicates the name used as the heading for the folding code\n\n\nExample of a folded code:\n\n\nExample of code fold\n```{r}\n#| code-fold: true\n#| code-summary: \"Example of code fold\"\n1 + 1\n```\n\n\n[1] 2",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#formating-the-report-and-results",
    "href": "resources/quarto_intro.html#formating-the-report-and-results",
    "title": "Introduction to Quarto",
    "section": "6.2 Formating the Report and Results",
    "text": "6.2 Formating the Report and Results\nAny text (outside of code chunks) is automatically formatted by Quarto. To present nicely formatted tables and figures, a variety of packages are available. This includes the gt and gtsummary packages for tables, and the ggplot package for figures.\nTo present executable code inline with your text, enclose the expression in `r `. For example:\nThe sum of 1 + 1 is equal to `r 1+1`.\nThe sum of 1 + 1 is equal to 2.",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#example-of-analyses-and-report",
    "href": "resources/quarto_intro.html#example-of-analyses-and-report",
    "title": "Introduction to Quarto",
    "section": "6.3 Example of Analyses and Report",
    "text": "6.3 Example of Analyses and Report\n\nSyntax + OutputOutput Only\n\n\n\n```{r}\n#| warning: false\n\n# Load libraries and data.\nlibrary(tidyverse)       # Data management\nlibrary(gt)              # Create nicely formatted tables\nlibrary(gtsummary)       # Create summary tables\nlibrary(palmerpenguins)  # Contains the dataframe called \"penguins\"\n\n\n# Lets calculate some numbers to be used later on\nn_Adelie    &lt;- filter(penguins, species==\"Adelie\") %&gt;% nrow()\nn_Chinstrap &lt;- filter(penguins, species==\"Chinstrap\") %&gt;% nrow()\nn_Gentoo    &lt;- filter(penguins, species==\"Gentoo\") %&gt;% nrow()\n```\n\nOur data is comprised of `r nrow(penguins)` peguins; specifically comprised of the\nspecies Adelie (n=`r n_Adelie`), Chinstrap (n=`r n_Chinstrap`), and Gentoo \n(n=`r n_Chinstrap`). Penguin charactersitics are presented in @tbl-demographics.\nOur data is comprised of 344 peguins; specifically comprised of the species Adelie (n=152), Chinstrap (n=68), and Gentoo (n=68). Penguin charactersitics are presented in Table 1.\n\n```{r}\n#| label: tbl-demographics\n#| tbl-cap: Penguin charactertics\n\npenguins %&gt;% \n  select(species, sex, flipper_length_mm, body_mass_g) %&gt;%\n  tbl_summary(\n      by=species,\n      missing = \"no\",\n      statistic = list(all_continuous() ~ \"{mean} ({sd})\",\n                       all_categorical() ~ \"{n} ({p}%)\"))\n```\n\n\n\nTable 1: Penguin charactertics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAdelie N = 1521\nChinstrap N = 681\nGentoo N = 1241\n\n\n\n\nsex\n\n\n\n\n\n\n\n\n    female\n73 (50%)\n34 (50%)\n58 (49%)\n\n\n    male\n73 (50%)\n34 (50%)\n61 (51%)\n\n\nflipper_length_mm\n190 (7)\n196 (7)\n217 (6)\n\n\nbody_mass_g\n3,701 (459)\n3,733 (384)\n5,076 (504)\n\n\n\n1 n (%); Mean (SD)\n\n\n\n\n\n\n\n\n\n\n\nOur analyses show that flipper length and body mass are related, see @fig-scatter.  \nOur analyses show that flipper length and body mass are related, see Figure 1.\n\n```{r}\n#| label: fig-scatter\n#| fig-cap: Flipper length by body mass\n#| fig-height: 4\n\nggplot(data = penguins, \n                       aes(x = flipper_length_mm,\n                           y = body_mass_g)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 3,\n             alpha = 0.8) +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Body mass (g)\",\n       color = \"Penguin species\",\n       shape = \"Penguin species\") +\n  theme_minimal() + \n  theme(legend.position = c(0.2, 0.7),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")\n```\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nFigure 1: Flipper length by body mass\n\n\n\n\n\n\n\nOur data is comprised of 344 peguins; specifically comprised of the species Adelie (n=152), Chinstrap (n=68), and Gentoo (n=68). Penguin charactersitics are presented in Table 1.\n\n\n\n\nTable 2: Penguin charactertics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAdelie N = 1521\nChinstrap N = 681\nGentoo N = 1241\n\n\n\n\nsex\n\n\n\n\n\n\n\n\n    female\n73 (50%)\n34 (50%)\n58 (49%)\n\n\n    male\n73 (50%)\n34 (50%)\n61 (51%)\n\n\nflipper_length_mm\n190 (7)\n196 (7)\n217 (6)\n\n\nbody_mass_g\n3,701 (459)\n3,733 (384)\n5,076 (504)\n\n\n\n1 n (%); Mean (SD)\n\n\n\n\n\n\n\n\n\n\n\nOur analyses show that flipper length and body mass are related, see Figure 1.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nFigure 2: Flipper length by body mass",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#html-basics",
    "href": "resources/quarto_intro.html#html-basics",
    "title": "Introduction to Quarto",
    "section": "8.1 HTML Basics",
    "text": "8.1 HTML Basics\nQuarto also support HTML, allowing for greater flexibility in formatting the final document. To use HTML, use triangle brackets: &lt; and &gt;; the formatting specified will be applied to the rest of the document, or until the code is ‘turned off’ by using the /.\nCommon HTML tags include:\n\n\n\nTag\nDescription\n\n\n\n\n&lt;h1&gt; to &lt;h6&gt;\nHeadings of different levels\n\n\n&lt;br&gt;\nLine break\n\n\n&lt;b&gt;\nBold text\n\n\n&lt;i&gt;\nItalic text\n\n\n&lt;div&gt;\nSection or container\n\n\n&lt;span&gt;\nInline styling or grouping of elements\n\n\n&lt;a&gt;\nHyperlink\n\n\n&lt;form&gt;\nForm container\n\n\n&lt;style&gt;\nCSS style declaration\n\n\n&lt;script&gt;\nJavaScript code\n\n\n\n For example:\nThis is how you &lt;b&gt;bold&lt;/b&gt; or &lt;i&gt;italicize&lt;/i&gt; words.\nThis is how you bold or italicize words.\n Similarly, you can use HTML’s &lt;div&gt; tag to create custom sections or containers with specific styles:\n&lt;div class=\"my_custom-section\"&gt;\nThis is a custom section with a specific style (specified below).\n&lt;/div&gt;\n  \nThis section defaults back to the original formatting. \n\nThis is a custom section with a specific style (specified below).\n\nThis section defaults back to the original formatting.",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#css-basics",
    "href": "resources/quarto_intro.html#css-basics",
    "title": "Introduction to Quarto",
    "section": "8.2 CSS Basics",
    "text": "8.2 CSS Basics\nHTML becomes even more powerful when you combine it with CSS (Cascading Style Sheets). CSS allows you to define styles and apply them to HTML elements, giving you full control over the document’s visual presentation. You can include CSS styles within your Quarto document using HTML’s &lt;style&gt; tag:\n&lt;style&gt;\n    .my_custom-section {\n        background-color: #e32424;\n        color: white;\n        padding: 10px;\n    }\n&lt;/style&gt;\n\nIn this example, we define a CSS style for the .my_custom-section class, specifying a background color, font color, and padding. This style will be applied to any &lt;div&gt; element with the my_custom-section class in your document.\nBy combining HTML and CSS, you can achieve a highly customized and visually appealing document layout.",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#pre-set-themes",
    "href": "resources/quarto_intro.html#pre-set-themes",
    "title": "Introduction to Quarto",
    "section": "8.3 Pre-set Themes",
    "text": "8.3 Pre-set Themes\nThere are a number of pre-specified themes available, and can be specified in the YAML.\nFor example:\n---\ntitle: My Report\nformat:\n  html:\n    theme: cerulean\n---\nQuarto uses Bootstrap themes, with details available here. There you can also examine the preset formatting of various types of objects and utilize it in your Quarto document.\nFor example:\n\n&lt;div class=\"alert alert-warning\"&gt;\n  &lt;h4 class=\"alert-heading\"&gt;Heading&lt;/h4&gt;\n  Your text here.\n&lt;/div&gt;\n\n\nHeading\n\nYour text here.",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#custom-themes",
    "href": "resources/quarto_intro.html#custom-themes",
    "title": "Introduction to Quarto",
    "section": "8.4 Custom Themes",
    "text": "8.4 Custom Themes\nTo create a custom theme or modify an existing, you will need to create a text file with an ending of “.scss”; this file will list your specifications.\n\n\n\n\n\n\nSASS: Syntactically Awesome Style Sheets\n\n\n\nSASS files have the “.scss” extension. These files extend the functionality of CSS by allowing for a more organized and modular stylesheets, making it easier to manage and maintain your styles.\n\n\nCreate the ‘.scss’ file by creating a new text file while still in RStudio; here we name it ‘mytheme.scss’:\n\nReference the file created in the YAML of your Quarto document; multiple theme files can be used:\n---\ntitle: My Report\nformat:\n  html:\n    theme: \n      - cerulean\n      - mytheme.scss\n---\nTo specify your theme, open the SASS file and list the specifications. Importantly, the file should begin with /*-- scss:defaults --*/. Here’s an example:\n\n/*-- scss:defaults --*/\n\n$blue: #1F3169;\n\n.my_custom-section2 {\n    background-color: $blue;\n    color: white;\n    padding: 10px;\n}\nThe advantage of SASS over CSS is that we can define colors or settings, to be used later. In the example above, we have assigned hex color #1F3169 the variable label of blue; this label can then be referred to in other sections of the code. In this example, we are using CSS to create a new class (like we did earlier), but here we specify the color as blue.\nThis becomes more powerful when combined with the pre-specified themes and settings of Quarto. Quarto has predefined SASS variables that can be changed and modified to adjust the appearance of your report. The available variables can be found here. If the variables listed there are not enough, the complete list can be found here; use the search function to identify variables that seem like they may change the feature you are interested in.\nOnce you have idenfied the variable, you can specify the value; the general form is: $variable_name: value;. Comments begin with a //.\nFor example:\n\n/*-- scss:defaults --*/\n\n// Color of the text in the body of the document.\n$body-color: #000000;\n  \n// Page background color.\n$body-bg: #fff;\n  \n// Font size (reference is 1rem).\n$font-size-base: 1.2rem;",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#other-formatting-examples",
    "href": "resources/quarto_intro.html#other-formatting-examples",
    "title": "Introduction to Quarto",
    "section": "8.5 Other Formatting Examples",
    "text": "8.5 Other Formatting Examples\n\n8.5.1 Watermmark\nTo add a watermark to a HTML document, you can use CSS code, like so:\n&lt;style&gt;\n.draft-watermark {\n    position: fixed; top: 50%; left: 50%;\n    transform: translate(-50%, -50%) rotate(-45deg);\n    font-size: 100px; font-weight: bold; color: #ccc; opacity: 0.5; }\n&lt;/style&gt;\n\n&lt;div class=\"draft-watermark\"&gt;Draft&lt;/div&gt;\nThe first part, enclosed within the &lt;style&gt; and &lt;/style&gt; lists the details of the watermark.\nThe second part, enclosed within the &lt;div&gt; and &lt;/div&gt; applies the settings specified.\n\n\n8.5.2 Collapsible Sections\nAlthough you can use ‘callouts’ to highlight or collapse sections, if you do not want the formatting that is associated with callouts, you can use HTML code.\n\n\n&lt;details&gt;\n&lt;summary&gt; Title here&lt;/summary&gt;\nDetails go here. This will be collapsed. \n&lt;/details&gt;\n\n\n\nTitle here\n\nDetails go here. This will be collapsed.",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "resources/quarto_intro.html#troubleshooting",
    "href": "resources/quarto_intro.html#troubleshooting",
    "title": "Introduction to Quarto",
    "section": "8.6 Troubleshooting",
    "text": "8.6 Troubleshooting\nIf something is not working but it should, you may just need to ensure that there is an empty line before/after the HTML tag.",
    "crumbs": [
      "R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "A cornerstone of my teaching philosophy is the alignment of learning outcomes, assessments, and active learning strategies. I take a ‘course-long perspective’ whereby assignments and activities are designed in relation to each other, each developing skills that are further reinforced by the next task. I also aim to provide opportunities to apply the course material through hands-on components. I strive to provide an engaging and supportive classroom environment through the utilization of various active learning techniques, such polls and games using iClickers/online platforms to review material, debates, and think-pair-share activities. The goal of such activities and classroom discussions is to engender a sense of community, learn from the perspectives of others, and allow for opportunities to apply, analyze, and evaluate during classroom discussions."
  },
  {
    "objectID": "teaching.html#western-university-london-on",
    "href": "teaching.html#western-university-london-on",
    "title": "Teaching",
    "section": "Western University (London, ON)",
    "text": "Western University (London, ON)\n\nCourses\n\n2021 - 2023  Biostatistics 9500: Epidemiology & Biostatistics  Graduate Orthodontics & Dentofacial Orthopaedics  Schulich School of Medicine & Dentistry,  Western University \n\n\n\nWorkshops\n\nJuly 2019  Data management and analysis using SAS.  Epidemiology & Biostatistics 2019 Summer Workshop Series,  Western University \nMay 2018  An applied introduction to analyzing and visualizing interactions in SAS.  Epidemiology & Biostatistics 2018 Summer Workshop Series,  Western University \nNov 2017  “I have my data! Now what?” SAS basics and data management.  Department of Epidemiology & Biostatistics,  Western University \n\n\n\nCertifications Received\n\nMay 2019  Advanced Teaching Program  Centre for Teaching and Learning, Western Univesity.  Completed a 20-hour course covering topics such as course design strategies, active learning, authentic assessment of student learning, and maintaining a culture of respect and community."
  },
  {
    "objectID": "resources/surveys_questions.html",
    "href": "resources/surveys_questions.html",
    "title": "Survey Design 2: Designing Effective Questions",
    "section": "",
    "text": "Topic: Review of empirically validated methods and strategies for designing effective surveys and questions.\nThis document follows the recommendations of the Tailored Design Method  by D.A. Dillman (2014).",
    "crumbs": [
      "Survey Design",
      "Designing Effective Questions"
    ]
  },
  {
    "objectID": "resources/surveys_questions.html#other-considerations",
    "href": "resources/surveys_questions.html#other-considerations",
    "title": "Survey Design 2: Designing Effective Questions",
    "section": "Other Considerations",
    "text": "Other Considerations\n\nEnsure the question is technically accurate. Using specialized terms commonly used and accepted among the survey population will likely produce a more accurate measurement.\nMake things as easy and simple as possible. Use complete sentences in question form, with a simple sentence structure and with simple and familiar words. Use specific and concrete words to specify the concept clearly. Do not be vague or allow room for varying interpretations.\nAnswer choices should include all reasonable possible answers and should be mutually exclusive.\nIn terms question length per line, a moderate line length of 3 to 5 inches is recommended.\n\nLong lines may make it difficult to track along the lines, and short lines require a lot of eye movement to move to the next line.\n\nChoose an appropriate scale length – long enough to represent the entire continuum of answers, but without so many categories that they begin to burden respondents or differences become meaningless.\n\nFor bipolar scales (e.g. questions asking for agreement and disagreement), 5 to 7 categories may be ideal. For unipolar scales (e.g. questions asking about level of concern), 4 to 5 may be ideal.\nFor bipolar questions, including a middle, neutral point, does not make much of an impact; neither does starting with positives vs. starting with negative items. You just need to be consistent.\n\nWhen considering non-substantive response options such as “don’t know”, “no opinion”, “undecided”, consider each question individually. Research is mixed and has found that such options may allow people to answer honestly or that it may provide an easy answer for those unmotivated.\nIf asking respondents to rank items, only ask them to rank a few items at a time, rather than a long list to reduce cognitive load.\nBeware of vague quantifiers (e.g. “sometimes”, “often”, etc.) that may mean different things to different people and mean different things for different questions.\nEnsure that question stem and answer options match. Use construct-specific scales; pose questions in a way that matches the response scale.\n\nFor example, do not ask “To what extent do you agree or disagree that you enjoyed the movie?” It is much easier to answer this question when it is phrased more directly: “How much, if at all, did you enjoy the movie?”",
    "crumbs": [
      "Survey Design",
      "Designing Effective Questions"
    ]
  },
  {
    "objectID": "resources/study_systematic_reviews.html",
    "href": "resources/study_systematic_reviews.html",
    "title": "Study Design 5: Systematic Reviews",
    "section": "",
    "text": "Topic: Review of systematic reviews and the steps involved in conducting your own review. A step-by-step example of the search strategy is also presented.\nImportantly, the guide below is brief and reviewing the Cochrane Handbook and working with a librarian and statistician is highly advisable.",
    "crumbs": [
      " Other Study Designs",
      "Systematic Reviews"
    ]
  },
  {
    "objectID": "resources/study_systematic_reviews.html#develop-a-study-protocol",
    "href": "resources/study_systematic_reviews.html#develop-a-study-protocol",
    "title": "Study Design 5: Systematic Reviews",
    "section": "1. Develop a study protocol",
    "text": "1. Develop a study protocol\nDevelop a study protocol to establish and document search strategy and methodology in advance. This should include clearly stated objectives, pre-defined eligibility criteria, systematic search strategy to identify all potential studies, an assessment of validity of included studies, and data to be collected.\nCriteria that will force the unnecessary exclusion of studies should be avoided.\nIt is encouraged that systematic reviews are registered at PROSPERO and/or protocols are published. Changes to the protocol are sometimes necessary, but should not be based on how they affect the outcome of the research study; changes should also be explicitly reported.",
    "crumbs": [
      " Other Study Designs",
      "Systematic Reviews"
    ]
  },
  {
    "objectID": "resources/study_systematic_reviews.html#search-for-articles",
    "href": "resources/study_systematic_reviews.html#search-for-articles",
    "title": "Study Design 5: Systematic Reviews",
    "section": "2. Search for articles",
    "text": "2. Search for articles\nSeeking the help of a research librarian is highly recommended to understand which databases may be relevant and how to access them, how to identify the proper keywords for the search, and other practical issues.\nThe search should be based on the main concepts being examined in the review. That is, use search terms relating the to 1) health condition of interest, 2) intervention of interest, 3) study design (e.g. randomized trial); avoid using too many different concepts. You should aim for high sensitivity; i.e. extensive search so that all eligible studies are identified and included. It is however, necessary to strike a balance between comprehensiveness and relevance.\nSearch using keywords and subject headings (also referred to as MeSH terms). Many databases can be searched using standardized subject headings (e.g. MeSH terms) that are assigned by the indexers. They provide a way of retrieving articles that may use different words to describe the same concept and provide information beyond keywords. To ensure you’re not missing important terms, examine articles you know fit your criteria and review the key words and MeSH terms associated with such articles. Use Boolean operators (AND, OR, and NOT) to facilitate the search (e.g. for alternate spelling / synonyms). Use asterisks for truncation (e.g. “random*” for random or randomised or randomized, etc), and ‘?’ for wildcard (e.g. “wom?n” for woman or women).\nMultiple databases should be used – e.g. MEDLINE, EMBASE, CINAHL, Web of Science, Scopus. The appropriate databases will depend on your review (e.g. PsychINFO for mental health topics). Clinical Trials registers and trials results registers are an increasingly important source of information to ensure that publication bias is minimized (e.g. to minimize the “file-drawer problem”). Forward and backward citation tracking should also be used (manually screening the studies that cite the studies in your review, and screening the reference list of the studies in the review, respectively).",
    "crumbs": [
      " Other Study Designs",
      "Systematic Reviews"
    ]
  },
  {
    "objectID": "resources/study_systematic_reviews.html#screening-identified-studies",
    "href": "resources/study_systematic_reviews.html#screening-identified-studies",
    "title": "Study Design 5: Systematic Reviews",
    "section": "3. Screening identified studies",
    "text": "3. Screening identified studies\nAll stages of the screening process must be completed by two people independently; this will substantially reduce the likelihood of errors; you should pre-specify the process of handling discrepant results.\nOnce the search is completed, and the citations extracted, upload the citations to your software program of choice to help facilitate the screening process (e.g. Covidence.org). Use the software to identify and delete duplicates, then screen articles in two stages. First, review titles and abstracts and remove obviously irrelevant reports (be overly inclusive). Second, retrieve full text of remaining articles and thoroughly review to determine whether all inclusion criteria are met; contact study corresponding authors if clarification is needed. Careful notes should be kept throughout the entire process documenting decisions, e.g. reasons for exclusion.",
    "crumbs": [
      " Other Study Designs",
      "Systematic Reviews"
    ]
  },
  {
    "objectID": "resources/study_systematic_reviews.html#collecting-data",
    "href": "resources/study_systematic_reviews.html#collecting-data",
    "title": "Study Design 5: Systematic Reviews",
    "section": "4. Collecting data",
    "text": "4. Collecting data\nIt is important that data extraction is completed by two people independently (to substantially reduce errors).\nData to be collected (e.g. study details, patient demographics, and outcomes) are identified a priori. Be cautious to avoid duplication of data – e.g. data from different articles, but reporting on the same study.\nContact study corresponding authors if clarification or other data are needed.",
    "crumbs": [
      " Other Study Designs",
      "Systematic Reviews"
    ]
  },
  {
    "objectID": "resources/study_systematic_reviews.html#assessment-of-risk-of-bias-validity",
    "href": "resources/study_systematic_reviews.html#assessment-of-risk-of-bias-validity",
    "title": "Study Design 5: Systematic Reviews",
    "section": "5. Assessment of Risk of Bias / Validity",
    "text": "5. Assessment of Risk of Bias / Validity\nIt is important that this assessment is completed by two people independently (to substantially reduce errors).\nThis is an important part of the review because problems with the design and execution of individual studies raise questions about the validity of their findings. Specific tools and checklists have been developed for different study designs.",
    "crumbs": [
      " Other Study Designs",
      "Systematic Reviews"
    ]
  },
  {
    "objectID": "resources/study_systematic_reviews.html#report-data-and-undertaking-meta-analyses",
    "href": "resources/study_systematic_reviews.html#report-data-and-undertaking-meta-analyses",
    "title": "Study Design 5: Systematic Reviews",
    "section": "6. Report Data and Undertaking Meta-Analyses",
    "text": "6. Report Data and Undertaking Meta-Analyses\nAnalyses may be narrative (e.g. a structured summary and discussion of the studies’ characteristics and findings), or quantitative (e.g. meta-analyses - involving statistical analysis). You may not know whether you can conduct a meta-analysis until all the data have been systematically collected; included studies may be very different from each other for their results to be combined, or they may not present data in a similar way to allow for direct comparisons.\nTables and figures help to present details and results of included studies in a systematic and clear format.",
    "crumbs": [
      " Other Study Designs",
      "Systematic Reviews"
    ]
  },
  {
    "objectID": "resources/study_chart_review.html",
    "href": "resources/study_chart_review.html",
    "title": "Study Design 2: Retrospective Chart Review",
    "section": "",
    "text": "Topic: Review of best practices and the steps involved in conducting a retrospective chart review.\n\nIntroduction\n\nRetrospective chart review research uses pre-recorded patient data (e.g. from patient charts) to answer one or more research questions. An important limitation to keep in mind is that the information was not originally collected for research purposes.\nStandardization is key to ensuring that the study data is of sound quality. A detailed study protocol and data collection form should be developed prior to the commencement of the study and data collection.\nA research ethics board (REB) application will be required and approval must be obtained prior to data collection. Individual participant consent is not likely required in these cases.\nThis study design is typically used to evaluate incidence, prevalence, clinical course/prognosis, determinants/outcomes of health service use, adherence to guidelines or standards of practice, etc.\n\n\n\nDefine and Articulate the Research Question\n\nClearly state your research question. Is your research goal to describe, associate, predict, or compare?\n\nDefine the PICO:  P = Patient/Problem;  I = Intervention;  C = Comparison;  O = Outcome \n\nYou may need to narrow your focus to what can be accomplished by the study with the given data.\n\nIt is also important to consider whether the database will have the information that will be needed to answer your research question, and that it is not missing for a large number of patients.\n\nConduct a literature review to evaluate how similar questions have been addressed in the past and to ensure the research question has not been sufficiently evaluated.\nExplicitly define the inclusion and exclusion criteria. Exclusion criteria may include substantive missing data, presence of comorbidities, etc.\n\n\n\nDevise the Sampling Strategy a priori\n\nRandom sampling – the gold standard, whereby each medical record has an equal opportunity of being selected. Enumerate a list of all patients meeting certain criteria, and sample at random.\n\nE.g. generate a random number for each person in Excel, then sort, then select the first XX people\n\nConvenience sampling – most common, whereby the researcher utilizes the medical information at their disposal. This method may be prone to sampling bias and limits generalizability.\n\nThis includes selecting all patients within a given timespan, which is acceptable if the timespan is long enough to include seasonal and other variations over time that may be relevant.\n\nSystematic sampling – whereby every k-th medical record is collected. This is not truly random and therefore may induce selection bias.\nConduct a sample size calculation to ensure the project is feasible for your research question.\n\n\n\nOperationalize Variables\n\nCreate a ‘data dictionary’ – an appendix of variable operationalization (e.g. variable labels, definitions) and how they should be coded.\nOperationalizing refers to “translating a construct into its manifestation”.\n\nE.g. you may be interested in pain or high blood pressure– how will these be measured/defined?\n\nOperationalization requires literature review to identify how others have operationalized the variable in the past; it is often better to adopt an existing, validated approach, as opposed to creating one.\n\n\n\nDevelop a Standardized Procedure and Data Collection Form\n\nCreate detailed and specific guidelines for data collection and coding to minimize interpretation of the data to be collected, and specify how discrepancies would be reconciled.\n\nProvide detailed instructions for recording potentially ambiguous information. For example, specify the categories of certain variable (e.g. never smokes, sometime smokes, etc.), and provide examples of descriptions of data that would fit into each category.\n\nCreate a standardized data collection form (DCF).\n\nDesign a DCF to follow the data flow/organization from the perspective of the data collectors.\n\nIf multiple data sources are used, separate DCFs may be helpful.\n\nLimit the amount of manual entry for numbers or text to minimize errors.\nLimit the use of skip patterns; if used, make instructions salient (e.g. highlight, use graphics).\nSpecify instructions for dealing with missing data; it is advisable that you distinguish between not completed, missing, or not applicable.\n\nUse paper or electronic forms; paper forms are easier to fill out so errors might be reduced, whereas electronic forms may save time and reduce transcription errors.\n\nREDCap (free, from Lawson) is a great electronic form. If using Excel, you should use the “data validation” feature to restrict the data that can be entered and to create drop down lists.\n\n\n\n\nTrain and Monitor Data Collectors\n\nIdeally, the data collectors will be blinded to the purpose of the study and research questions; this would significantly reduce reviewer bias.\nTraining for the collection of data should include a careful review of the variables, procedure, and DCF.\n\nData collectors should review/code several patient records for practice, which should be carefully verified by the researcher; any discrepancy should be discussed, and any issues clarified.\n\nSchedule recurrent meetings to monitor progress and to discuss/clarify any new issues or scenarios.\nCan apply the 100-20 rule: 100% of the data are checked for 20% of the participants, and 20% of the most essential data are checked in 100% of the participants.\nThe study can be further strengthened by assessing/reporting intra-rater and inter-rater reliability to describe the coding consistency within and between raters, respectively (e.g. Cohen’s kappa, ICC)\n\n\n\nPilot Test the Process and Forms\n\nPilot testing is essential to assess the study design, procedures and its feasibility, and highlight the frequency that key variables of interest are missing from patient records.\n\nThe pilot sample should be randomly sampled and consist of 10% of the target sample size.\n\n\n\n\nReferences and Further Readings\nMatt V, Matthew H. The retrospective chart review: important methodological considerations. Journal of educational evaluation for health professions. 2013;10.\nJansen AC, et al. Guidelines were developed for data collection from medical records for use in retrospective analyses. Journal of clinical epidemiology. 2005;58(3):269-74.\nFor more on PICO: https://researchguides.uic.edu/c.php?g=252338&p=3954402",
    "crumbs": [
      " Other Study Designs",
      "Chart Review"
    ]
  },
  {
    "objectID": "resources/study_case_control.html",
    "href": "resources/study_case_control.html",
    "title": "Study Design 1: Case Control",
    "section": "",
    "text": "Topic: Review of case-control study designs, and methodological considerations.",
    "crumbs": [
      " Other Study Designs",
      "Case Control"
    ]
  },
  {
    "objectID": "resources/study_case_control.html#traditional-case-control",
    "href": "resources/study_case_control.html#traditional-case-control",
    "title": "Study Design 1: Case Control",
    "section": "Traditional Case-Control",
    "text": "Traditional Case-Control\n\nCases and controls are selected at the time of the study\n\nThe disease/outcome occurred sometime in the past for cases\nControls are selected from the study base that gave rise to cases\nPotential survival bias – only cases that survive long enough are included in the study\n\nDepending on case definition and data source, both incident and prevalent cases may be included\nThe calculated odds ratio (OR) approximates the relative risk or rate ratio (RR) if the rare disease assumption is met (i.e. if the prevalence of disease/outcome is &lt;10%)",
    "crumbs": [
      " Other Study Designs",
      "Case Control"
    ]
  },
  {
    "objectID": "resources/study_case_control.html#case-cohort",
    "href": "resources/study_case_control.html#case-cohort",
    "title": "Study Design 1: Case Control",
    "section": "Case-Cohort",
    "text": "Case-Cohort\n\nThis is a case-control study within a cohort study\nBegin with a cohort, and measure baseline characteristics\nParticipants are followed over time, and those that develop the outcome become your cases\nControls are selected as a random sample of the total cohort at baseline\n\nBecause controls come from baseline period, survival bias is removed\nControl group may include individuals who become cases during the later follow-up periods\n\nAdvantages:\n\nSave on costs/resources; e.g. analyze blood sample of a handful of controls instead of the thousands of blood samples collected and frozen at baseline\nSelection bias diminished since cases and controls are selected from the same (defined) source cohort and exposure is assessed before the disease/outcome occurs\nThe OR approximates the RR, even if the rate disease assumption is not met",
    "crumbs": [
      " Other Study Designs",
      "Case Control"
    ]
  },
  {
    "objectID": "resources/study_case_control.html#nested-case-control",
    "href": "resources/study_case_control.html#nested-case-control",
    "title": "Study Design 1: Case Control",
    "section": "Nested case-control",
    "text": "Nested case-control\n\nSimilar to case-cohort study, with one difference: controls are a random sample of the individuals remaining in the cohort at the time each case occurs\n\nIs a variant of case-cohort that matches cases and controls on time; is equivalent to matching cases and controls on duration of follow-up\nCases occurring later in the follow-up are eligible to be controls for earlier cases\n\nConsidered gold standard of case-control designs\nThe OR approximates the RR, even if the rate disease assumption is not met",
    "crumbs": [
      " Other Study Designs",
      "Case Control"
    ]
  },
  {
    "objectID": "resources/sample_size_calculator.html",
    "href": "resources/sample_size_calculator.html",
    "title": "Sample Size Calculator",
    "section": "",
    "text": "Sample size calculations form an important part of the study design, but the formula and implementation of sample size calculations can be complex and intimidating. The sample size calculator below was designed guide researchers through the process of calculating a sample size using a simple to use and informative interface.\nThe sample size calculator is based on the formula described by Vittinghoff et al. (2012). The calculations are based on Linear Regression for continuous outcomes, Logistic Regression for binary outcomes, Poisson Regression for count data as the outcome, and Cox Models (Survival Analyses) for time-to-event outcomes.",
    "crumbs": [
      "Getting Started",
      "Sample Size Calculator"
    ]
  },
  {
    "objectID": "resources/sample_size_calculator.html#example-1-continuous-outcome",
    "href": "resources/sample_size_calculator.html#example-1-continuous-outcome",
    "title": "Sample Size Calculator",
    "section": "Example 1: Continuous Outcome",
    "text": "Example 1: Continuous Outcome\nEstimate the sample size for a randomized trial with equal allocation to treatment and placebo to assess the effect of a new lipid-lowering agent on LDL levels. From pilot data, the standard deviation for LDL is expected to be 38 mg/dL, and it is hypothesized that the treatment will lower average LDL levels about 40 mg/dL. Because this is a clinical trial, it is unlikely that we will need to adjust for covariates. The sample size must provide 80% power in a two-sided test with \\(\\alpha\\) of 5%.\nEnter the following in the sample size calculator above:\n\nType of outcome variable: Continuous\nType of independent variable: Binary\nMinimum detectable effect: 40\nStandard deviation of the outcome: 38\nProportion of participants in group of interest: 0.5\nMultiple correlation: 0\nFalse positive rate: 0.05\nStatistical power: 0.80\nAnticipated attrition rate: 0\n\nTotal sample size required: 28",
    "crumbs": [
      "Getting Started",
      "Sample Size Calculator"
    ]
  },
  {
    "objectID": "resources/sample_size_calculator.html#example-2-binary-outcome",
    "href": "resources/sample_size_calculator.html#example-2-binary-outcome",
    "title": "Sample Size Calculator",
    "section": "Example 2: Binary Outcome",
    "text": "Example 2: Binary Outcome\nEstimate the sample size for a observational study comparing the incidence of an adverse postsurgical outcome from a new technique. From past studies, we expect that the incidence is 15% and 5% for the two techniques. We also expect to have an equal proportion of patients in both groups, 10% attrition, and we will not be adjusting for any other variables (i.e., multiple correlation = 0). Lastly, we assume 80% power in a two-sided test with \\(\\alpha\\) of 5%.\nTo solve, we must first convert the proportions into an odds ratio (OR): \\[ OR = \\frac{\\text{Odds in new group}}{\\text{Odds in old group}} = \\frac{0.05/0.95}{0.15/0.85} = 0.30 \\]\nAdditionally, given that two groups will be the same size, the marginal prevalence of adverse events is 10%.\nEnter the following in the sample size calculator above:\n\nType of outcome variable: Binary\nType of independent variable: Binary\nMinimum detectable odds ratio: 0.30\nMarginal probability of outcome: 0.10\nProportion of participants in group of interest: 0.5\nMultiple correlation: 0.0\nFalse positive rate: 0.05\nStatistical power: 0.80\nAnticipated attrition rate: 0.10\n\nTotal sample size required: 267",
    "crumbs": [
      "Getting Started",
      "Sample Size Calculator"
    ]
  },
  {
    "objectID": "resources/sample_size_calculator.html#example-3-time-to-event-outcome",
    "href": "resources/sample_size_calculator.html#example-3-time-to-event-outcome",
    "title": "Sample Size Calculator",
    "section": "Example 3: Time-to-event Outcome",
    "text": "Example 3: Time-to-event Outcome\nEstimate the sample size providing 80% power in a two-sided test with \\(\\alpha\\) of 5% to detect an effect of bilirubin levels on survival. We hypothesize that the hazard ratio per mg/dL increase in bilirubin will be 1.15, adjusting for the effects of hepatomegaly, edema, and spiders. Past studies suggest an estimated 15% cumulative mortality over the study period, the standard deviation of bilirubin is 4.5 mg/dL, and the other variables adjusted for in the model are estimated to account for 20% of the variance in bilirubin. Lastly, assume that 10% of participants will be lost to follow-up.\nEnter the following in the sample size calculator above:\n\nType of outcome variable: Time-to-event\nType of independent variable: Continuous\nMinimum detectable hazard ratio: 1.15\nProportion of uncensored observation: 0.15\nStandard deviation of the outcome: 4.5\nMultiple correlation: 0.20\nFalse positive rate: 0.05\nStatistical power: 0.80\nAnticipated attrition rate: 0.10\n\nTotal sample size required: 184",
    "crumbs": [
      "Getting Started",
      "Sample Size Calculator"
    ]
  },
  {
    "objectID": "resources/sample_size_calculator.html#example-4-count-data-as-outcome",
    "href": "resources/sample_size_calculator.html#example-4-count-data-as-outcome",
    "title": "Sample Size Calculator",
    "section": "Example 4: Count data as Outcome",
    "text": "Example 4: Count data as Outcome\nEstimate the sample size for a randomized trial to assess the effectiveness of a behavioral intervention for reducing syringe sharing among drug users. Equal numbers will be allocated to the intervention and wait-list control. Because of randomization, we can assume that the multiple correlation is 0 (no variables are associated with the group assignment). From pilot data, we estimate that the an average of 7.5 syringes are shared among drug users, and the ratio of variance to the mean of the outcome is 30. We hypothesize that the intervention will reduce the frequency of sharing by 50% (i.e., rate ratio = 0.50). In this case we require power of 90% in a two-sided test with \\(\\alpha\\) of 5%, and we estimate that 15% of participants will be lost to follow-up.\nEnter the following in the sample size calculator above:\n\nType of outcome variable: Count data\nType of independent variable: Binary\nMinimum detectable rate ratio: 0.50\nMarginal mean of the outcome: 7.5\nDispersion: 30\nProportion of participants in group of interest: 0.5\nMultiple correlation: 0.0\nFalse positive rate: 0.05\nStatistical power: 0.9\nAnticipated attrition rate: 0.15\n\nTotal sample size required: 412",
    "crumbs": [
      "Getting Started",
      "Sample Size Calculator"
    ]
  },
  {
    "objectID": "resources/regression_survival.html",
    "href": "resources/regression_survival.html",
    "title": "Regressions 3: Survival Analysis",
    "section": "",
    "text": "Topic: Introduction to survival analysis methods, including Kaplan Meier curves and the Cox proportional hazards model, and interpretation of hazard ratios.",
    "crumbs": [
      "Regressions",
      "Survival Analyses"
    ]
  },
  {
    "objectID": "resources/regression_survival.html#kaplan-meier-curves",
    "href": "resources/regression_survival.html#kaplan-meier-curves",
    "title": "Regressions 3: Survival Analysis",
    "section": "Kaplan-Meier Curves",
    "text": "Kaplan-Meier Curves\nKaplan-Meier curves are used to plot the survival function, S(t), for one or more groups of interest over a specified time period. The Kaplan-Meier estimator assesses the probability of being event-free in a given amount of time. This method cannot control or take into account the effects of other covariates on the outcome of interest. The figure below shows the typical components of a Kaplan-Meier curve, for a single group of patients where the event of interest is discontinuation of a drug.\n Image source: https://doi.org/10.1038/jid.2015.171\nPlotting multiple curves for different treatment groups can allow for easy visual comparison of differences in survival probabilities. A log rank test can be used to test the null hypothesis that the Kaplan-Meier curves are equal at all time points. Rejecting the null hypothesis from a log rank test means there is evidence that there is at least 1 time point where the survival curves differ.",
    "crumbs": [
      "Regressions",
      "Survival Analyses"
    ]
  },
  {
    "objectID": "resources/regression_survival.html#the-hazard-ratio-the-proportional-hazards-assumption",
    "href": "resources/regression_survival.html#the-hazard-ratio-the-proportional-hazards-assumption",
    "title": "Regressions 3: Survival Analysis",
    "section": "The Hazard Ratio & The Proportional Hazards Assumption",
    "text": "The Hazard Ratio & The Proportional Hazards Assumption\nAs indicated above, the hazard function is the probability of the event occurring in a small period of time. Assume for a moment that we had the hazard functions for two groups of patients, group A and group B, we could compare the hazard function of one group to the other group by taking the ratio of the two functions, to give us the hazard ratio (HR).\n\\[\nHR(t) = \\frac{\\lambda_A(t)}{\\lambda_B(t)}\n\\]\nThe hazard ratio (HR), is dependent on time, however, if the hazard functions being compared are proportional over time, then HR will be constant over time and the effect of being in group A versus B can be summarized by a single number, namely the HR. This is known as the proportional hazards assumption and is the basis for the Cox Proportional Hazards Model.",
    "crumbs": [
      "Regressions",
      "Survival Analyses"
    ]
  },
  {
    "objectID": "resources/regression_survival.html#cox-proportional-hazards-model",
    "href": "resources/regression_survival.html#cox-proportional-hazards-model",
    "title": "Regressions 3: Survival Analysis",
    "section": "Cox Proportional Hazards Model",
    "text": "Cox Proportional Hazards Model\nThe Cox proportional hazards model is a regression analysis that allows us to estimate hazard ratios for survival data while controlling for the effects of multiple covariates. This method is related to Linear Regression and Logistic Regression and readers unfamiliar with regression techniques should read these topics first.\nUnder the proportional hazards assumption, a Cox proportional hazards (or Cox PH) model assumes that the log hazard ratio can be expressed as a linear function of the covariates:\n\\[\nlog(HR) = \\beta_1X_1 + ... + \\beta_nX_n\n\\]\nThe coefficient \\(\\beta\\) is the change in the log-hazard ratio for a one-unit increase in the covariate X. To interpret model results as hazard ratios we must exponentiate the coefficients (i.e., e\\(\\beta\\)). Hazard ratios can be interpreted as follows:\n\nHR&lt;1 means that a one unit increase in the covariate is associated with lower risk and longer survival times, controlling for other covariates. For example, a Hazard Ratio of 0.5 means that the estimated short term event risk for participants with the covariate is 50% of the risk for patients without the covariate.\nHR&gt;1 means that a one unit increase in the covraiate is associated with higher risk and shorter survival times. For example, a Hazard Ratio of 2 means that the estimated short term event risk for participants with the covraiate is two times greater than the risk for patients without the covraiate.\nHR= 1 means that the predictor is not associated with survival time.",
    "crumbs": [
      "Regressions",
      "Survival Analyses"
    ]
  },
  {
    "objectID": "resources/regression_logistic.html",
    "href": "resources/regression_logistic.html",
    "title": "Regressions 2: Logistic Regression",
    "section": "",
    "text": "Topic: Review of logistic regression and interpretation of results.\n\nIntroduction\nThis document extends the concepts of Linear Regression to binary outcomes. Binary outcomes have two states (e.g. alive or dead; yes or no) and are summarized using proportions. Logistic regression is an extension of simply comparing proportions, to allow for the adjustment of other independent variables. The results are presented as odds ratio (OR).\n\n\nReview of Odds Ratio\nSee the Working with Categorical Data for more details.\nBrieftly, the odds ratio (OR) is the ratio of the odds:\n\\[ Odds = \\frac{\\text{number of people with disease/outome}}{\\text{number of people without disease/outome}} \\]\n\\[ Odds Ratio (OR) = \\frac{\\text{Odds of Group A}}{\\text{Odds of Group B}} \\]\nInterpretation of OR: If OR = 4.89, we say that the odds of disease/outcome is 4.89 times higher in Group A, relative to Group B. Alternatively, can indicate that the odds are 389% (i.e. [4.89 - 1.00] x100%) higher in Group A, relative to Group B.\nAn OR of 1.0 indicates no association. If the 95% CI of the OR does not include the value of 1, this indicates that the difference between groups is statistically significant at p&lt;.05.\n\n\nWhy not use Linear Regression\nRecall, in linear regression there is a continuous outcome variable (Y), the expected value or mean of which is assumed to be linearly related to the predictor/covariate (X). For a binary outcome, if its values are coded as 1 = ‘event occurs’ and 0 = ‘event does not occur’, the mean value is equivalent to the probability (p) that the event occurs. In principle, we could therefore use the linear regression technique to model the mean of the binary outcome; but we would run into some problems: 1. Probabilities must lie between 0 and 1, but the linear regression function can take on any real number; i.e., predicted probability can be that are greater than 1 or less than 0. 2. Probabilities generally exhibit nonlinear, S-shaped, relationships with covariates (see Figure example); i.e., the rate of change in the probability reduces (in absolute terms) as its value approaches zero or one.\nOne solution is to transform the probabilities to a scale that can take on any real number. This can be achieved using the logit or ‘log odds’ transformation. If p is the probability of the outcome, the logit transformation is defined as:\n\\[ logit(p) = log_e(odds) = log_e(\\frac{p}{1-p}) \\]\nA logistic regression uses these transformed probabilities in the model. Note that statistical software does this transformation automatically; it is discussed here to provide users with a better understanding of what the statistical software is doing.\n\n\nLogistic Regression\nIn the simplest case, we have one predictor variable (x) (e.g. group, defined as treatment [coded as 1] or control [coded as 0]). Similarly to linear regression, the logistic regression model can be written as\n\\[ logit(p) = β_0 + (β_1)(X) \\]\nβ0 = the log of the odds of the outcome occurring when x = 0 (e.g. the control group).\nβ1 = the log of the odds of the outcome occurring when x increases by 1 (e.g. the treatment group).\nExponentiating β (anti-loge) yields the odds ratio (i.e.: eβ = OR; e^β = OR)\nThe real value of logistic regression comes when we want to adjust for covariates (confounders). Covariates can be binary, categorical, or continuous; outcome must be binary. As with linear regression, multiple covariates (e.g. x1, x2) are specified by adding additional terms:\n\\[ logit(p) = β_0 + (β_1)(X_1)+ (β_2)(X_2)\\]\ne^β1 = the OR associated with increasing X1 by 1 unit, while all other variables (e.g. X2) stay the same.\ne^β2 = the OR associated with increasing X2 by 1 unit, while all other variables (e.g. X1) stay the same.\nThe model also produces a measure of statistical precision of the estimated coefficient (β) - the standard error, which are used to create the 95% confidence intervals.\n\n\nAssumptions and Other Considerations\nLogistic model assumes that: - The outcome is a binary variable - There is a linear relationship between the logit of the outcome and each predictor/covariate - There are no influential values (extreme values or outliers) in continuous predictors/covariates. - There is no multicolinearity (high correlations between predictors/covariates)\nThe selection of variables methods described in the Linear Regression resource can be extrapolated and applied to logistic regression as well.\n\n\nOdds Ratio (OR) vs. Relative Risk (RR)\nIt is important to note that OR estimates the ‘odds’ of an event occurring - i.e. the probability of the event occurring divided by the probability of the event not occurring. OR does not describe the ‘risk’ of the event occurring - i.e. the probability of the occurrence of the event; this is described by the RR.\nOften, researchers are interested in talking about the risk associated with a predictor/covariate, but may utilize logistic regression (and calculate the OR). Although risk and odds seem similar, there are important differences: - The OR will approximate the RR only when the prevalence of outcome is low (i.e. &lt;10%). Otherwise, the OR will greatly exaggerate the RR - With case-control data, only OR can be calculated. - With cohort studies, when data is available on the entire population/cohort, the RR may be calculated using different models (e.g. modified Poisson regression).\nSee Working with Categorical Data for a greater explanation.\n\n\nReferences and Further Readings\nWiest MM, Lee KJ, Carlin JB. Statistics for clinicians: An introduction to logistic regression. Journal of paediatrics and child health. 2015 Jul;51(7):670-3.\nKim HY. Statistical notes for clinical researchers: logistic regression. Restor Dent Endod. 2017;42(4):342-348.",
    "crumbs": [
      "Regressions",
      "Logistic Regression"
    ]
  },
  {
    "objectID": "resources/rct_randomization.html",
    "href": "resources/rct_randomization.html",
    "title": "Clinical Trials 2: Randomization",
    "section": "",
    "text": "Topic: Review of randomization, its importance, and the different options for randomization. How to generate a randomization list with R is also discussed.\nFor more information on clinical trials, I recommend the book  Statistical Issues in Drug Development by Dr. Senn.",
    "crumbs": [
      "Clinical Trials",
      "Randomization"
    ]
  },
  {
    "objectID": "resources/rct_randomization.html#simple-randomization",
    "href": "resources/rct_randomization.html#simple-randomization",
    "title": "Clinical Trials 2: Randomization",
    "section": "Simple randomization",
    "text": "Simple randomization\nPatients are assigned to each group at random for every assignment. This is akin to a coin flip for each patient assignment, and consequently you may not end up with an equal number of patients in each group, especially when the sample size is small. This method is not recommended for studies with a small sample size (e.g. &lt;100 patients).",
    "crumbs": [
      "Clinical Trials",
      "Randomization"
    ]
  },
  {
    "objectID": "resources/rct_randomization.html#block-randomization",
    "href": "resources/rct_randomization.html#block-randomization",
    "title": "Clinical Trials 2: Randomization",
    "section": "Block randomization",
    "text": "Block randomization\nEnsures that a similar number of patients are assigned to each group at any time during the study. Patients subgroups (called ‘blocks’) are created, then patients within each block are randomized such that an equal number of patients are assigned to each treatment group within each block. For example, when there are two treatment groups (A and B) and the block size is 4, if the first person is randomized to A, and the second to A, then the 3rd and 4th patient will be assigned to group B. This ensures that similar number of patients are assigned to each treatment group, while ensuring that each patient has an equal probability of being allocated to each group.\nHaving similarly sized groups minimizes the standard error of the treatment effect and therefore maximizes the statistical power. The disadvantage of blocked randomization is that it may be possible to guess some allocations, thereby breaking allocation concealment. However, allocation concealment is maintained if the block size is set to vary at random; e.g. using a mixture of blocks of size 2, 4, or 6. This may be your ideal choice; blocked randomization with randomly permuted block sizes.",
    "crumbs": [
      "Clinical Trials",
      "Randomization"
    ]
  },
  {
    "objectID": "resources/rct_randomization.html#stratified-randomization",
    "href": "resources/rct_randomization.html#stratified-randomization",
    "title": "Clinical Trials 2: Randomization",
    "section": "Stratified randomization",
    "text": "Stratified randomization\nIs used when there is a key variable measurable at the time of randomization that is considered to be strongly associated with the primary outcome (e.g. study site). It ensures that the treatment groups are balanced with respect to that variable (e.g. study site).\nA separate randomization list (created through simple or blocked randomization) is created for each stratum (e.g. for each category of the variable; e.g. for each study site). The randomization list specifies the sequence of treatment allocation, e.g. 1st patient will receive treatment, 2nd will receive treatment, 3rd will receive placebo, etc. When stratifying by $$2 variables, the number of randomization lists is the product of the number of categories. E.g. to stratify by site (4 sites) and sex (2 categories), the number of randomization lists should be 8 (i.e., 4 x 2); 1st list for site 1, males; 2nd list for site 1, females; 3rd list for site 2, males; etc.",
    "crumbs": [
      "Clinical Trials",
      "Randomization"
    ]
  },
  {
    "objectID": "resources/rct_design.html",
    "href": "resources/rct_design.html",
    "title": "Clinical Trials 1: Study Design",
    "section": "",
    "text": "Topic: Introduction to basic concepts of clinical trials and their categorization.\nFor more information on clinical trials, I recommend the book  Statistical Issues in Drug Development by Dr. Senn.",
    "crumbs": [
      "Clinical Trials",
      "Study Design"
    ]
  },
  {
    "objectID": "resources/rct_design.html#parallel-group-trial",
    "href": "resources/rct_design.html#parallel-group-trial",
    "title": "Clinical Trials 1: Study Design",
    "section": "Parallel-group trial",
    "text": "Parallel-group trial\nPatients randomized to treatment group and followed simultaneously to determine the effect of each treatment.",
    "crumbs": [
      "Clinical Trials",
      "Study Design"
    ]
  },
  {
    "objectID": "resources/rct_design.html#crossover-trial",
    "href": "resources/rct_design.html#crossover-trial",
    "title": "Clinical Trials 1: Study Design",
    "section": "Crossover trial",
    "text": "Crossover trial\nPatients receive a sequence of different treatments. Each person serves as their own control. There must be a sufficient time gap (‘washout period’) between different treatment phases.",
    "crumbs": [
      "Clinical Trials",
      "Study Design"
    ]
  },
  {
    "objectID": "resources/rct_design.html#factorial-trials",
    "href": "resources/rct_design.html#factorial-trials",
    "title": "Clinical Trials 1: Study Design",
    "section": "Factorial trials",
    "text": "Factorial trials\nEvaluate the effect of more than one treatment. Allows assessment of potential interaction among the treatments.",
    "crumbs": [
      "Clinical Trials",
      "Study Design"
    ]
  },
  {
    "objectID": "resources/rct_design.html#cluster-randomized-trials",
    "href": "resources/rct_design.html#cluster-randomized-trials",
    "title": "Clinical Trials 1: Study Design",
    "section": "Cluster Randomized Trials",
    "text": "Cluster Randomized Trials\nIntact groups (i.e. clusters) are randomized to different interventions, and outcomes are typically measured on individuals within those clusters. Clustered trials are discussed in further detail below. - Example: randomizing of the entire community or hospital to different interventions.",
    "crumbs": [
      "Clinical Trials",
      "Study Design"
    ]
  },
  {
    "objectID": "resources/rct_design.html#individually-randomized-group-treatment-trials",
    "href": "resources/rct_design.html#individually-randomized-group-treatment-trials",
    "title": "Clinical Trials 1: Study Design",
    "section": "Individually-randomized group treatment trials",
    "text": "Individually-randomized group treatment trials\nThis is a type of clustered trial, whereby individuals are individually randomized to different interventions, with groups (i.e. clusters) formed after randomization, and outcomes are typically measured on individuals within those clusters. Clustered trials are discussed in further detail below. - Example: psychological intervention that is delivered in a group setting.",
    "crumbs": [
      "Clinical Trials",
      "Study Design"
    ]
  },
  {
    "objectID": "resources/rct_design.html#why-are-clustered-trials-used",
    "href": "resources/rct_design.html#why-are-clustered-trials-used",
    "title": "Clinical Trials 1: Study Design",
    "section": "Why Are Clustered Trials Used",
    "text": "Why Are Clustered Trials Used\nClustered trials may be the best option when investigators want to evaluate an intervention that 1) operates at a group level, 2) manipulates the social or physical environment, 3) when interventions are delivered in groups, 4) cannot be delivered to individuals without ‘contamination’ (e.g. ‘spill-over’ effects). For example, a trial evaluating patient outcomes following an educational program for clinicians must use a clustered trial design, whereby clinicians (i.e. the cluster) are randomized, as opposed to randomizing patients. This is because of ‘spill-over’ effects, in that clinicians will utilize the materials learned for all patients; they cannot “use” the materials learned for some patients, and not others.\nDue to the challenges outlined below, clustered trials should be avoided unless individually randomized trials are scientifically inferior or practically impossible.",
    "crumbs": [
      "Clinical Trials",
      "Study Design"
    ]
  },
  {
    "objectID": "resources/rct_design.html#statistical-challenges-of-clustered-trials",
    "href": "resources/rct_design.html#statistical-challenges-of-clustered-trials",
    "title": "Clinical Trials 1: Study Design",
    "section": "Statistical Challenges of Clustered Trials",
    "text": "Statistical Challenges of Clustered Trials\nA common assumption of standard statistical methods is that observations (e.g. patients) are independent. This assumption is violated in clustered trials since individuals within a cluster are more likely to have similar outcomes. This creates special methodological challenges in design and analysis. Therefore, application of standard statistical methods are not appropriate and will generally bias p-values downwards; that is, could lead to spurious statistical significance (Type I error).\nMultilevel models are used for analyses to allow individual and group characteristics to be taken into account. It would be a mistake to ignore clustering effects simply because the observed ICC is close to zero or on the basis of significance tests. Clustering should be accounted for if it was part of the study design.\nSpecial sample size formula are available for clustered trials as a result of the challenges outlined above; the STATA clsampsi command may helpful, though working with a statistician is advisable. The statistical power of clustered trials may be substantially lower compared to a similarly-sized non-clustered trial, i.e. clustering makes it harder to detect differences between groups. It is harder to detect differences when the ‘design effect’ is higher.\nThe ‘design effect’, is given by: 1 + \\(\\rho\\) (m - 1),\nwhere m = average cluster size (e.g. group size), and\n\\(\\rho\\) = intra-cluster correlation (ICC), the correlation among participants within a cluster. The ICC is also interpretable as the proportion of overall variation in the outcome that can be attributable to clusters.\nThe design effect is small when the group and ICC is small. Generally, increasing the number of clusters offers more increase in power than increasing the number of individuals per cluster. The extant literature on your target population and intervention should be used to estimate your ICC. The ICC tends to be larger for knowledge and attitudes, smaller for behaviors, and even smaller for physiologic measures. As a very general guide, for health related outcomes the ICC values may be (Murray 2016): - 0.00 - 0.05 for large aggregates (such as hospitals, schools, worksites) - 0.05 - 0.25 for small aggregates (such as departments, classrooms) - 0.25 - 0.75 for very small aggregates (such as families, spouse pairs)",
    "crumbs": [
      "Clinical Trials",
      "Study Design"
    ]
  },
  {
    "objectID": "resources/rct_design.html#other-considerations-for-clustered-trials",
    "href": "resources/rct_design.html#other-considerations-for-clustered-trials",
    "title": "Clinical Trials 1: Study Design",
    "section": "Other Considerations for Clustered Trials",
    "text": "Other Considerations for Clustered Trials\nMethodological Considerations. Recruitment bias in recruiting individuals within a cluster; that is, clusters (e.g. hospitals) randomized to the new (exciting), treatment may be more eager to recruit individual patients, relative to the cluster randomized to the usual, control treatment.\nEthical considerations. If the intervention is offered at the cluster level, it is typically not possible to obtain consent before its administration (e.g., media campaigns designed to prevent drunk driving). “The roles of the guardians of the patients’ interests during the trial, the gatekeepers of access to patient groups, and sponsors of the research are even more important in cluster randomized trials where individuals may not have the opportunity to give informed consent to participation.” (MRC 2002). Norms regarding the need to obtain informed consent have yet to receive full acceptance.\nReporting. Reporting guidelines for clustered trials are available and should be followed (Campbell 2004). Principle additions include rational for adopting a cluster design, specifying how effects of clustering were incorporated into the sample size calculation and analysis, and an updated flow chart diagram.",
    "crumbs": [
      "Clinical Trials",
      "Study Design"
    ]
  },
  {
    "objectID": "resources/rct_other.html",
    "href": "resources/rct_other.html",
    "title": "Clinical Trials 3: Other Considerations",
    "section": "",
    "text": "Topic: Review of important considerations for clinical trials are outlined, including intention to treat principle; baseline comparisons and p-values; covariate adjustment; analyses of pre-post data, missing data, and interim events.\nFor more information on clinical trials, I recommend the book  Statistical Issues in Drug Development by Dr. Senn.",
    "crumbs": [
      "Clinical Trials",
      "Other Considerators"
    ]
  },
  {
    "objectID": "resources/rct_other.html#what-is-itt",
    "href": "resources/rct_other.html#what-is-itt",
    "title": "Clinical Trials 3: Other Considerations",
    "section": "What is ITT?",
    "text": "What is ITT?\nThe Intention to Treat (ITT) principle is a cornerstone in the interpretation of randomized controlled trials (RCT). Aims to provide unbiased results and preserve the integrity of the randomization. Following ITT, participants are analyzed as members of the treatment group to which they were randomized, regardless of their adherence to, or whether they received the intended treatment\nEliminating study participants who were randomized but not treated or moving participants between treatment groups according to the treatment they received would violate the ITT principle. ITT ignores noncompliance, protocol deviations, withdrawal, and anything that happens after randomization. It follows the principle of “once randomized, always analyzed”.\nBecause all patients must be analyzed under the ITT principle, it is essential that all patients be followed up and their primary outcomes determined, even those who withdraw from treatment. Following the ITT principle will not eliminate bias associated with missing outcome data.",
    "crumbs": [
      "Clinical Trials",
      "Other Considerators"
    ]
  },
  {
    "objectID": "resources/rct_other.html#why-is-itt-used",
    "href": "resources/rct_other.html#why-is-itt-used",
    "title": "Clinical Trials 3: Other Considerations",
    "section": "Why is ITT used?",
    "text": "Why is ITT used?\nIt preserves the integrity of the randomization process.\nAny deviations from strict ITT leads to the potential for bias and should be avoided. Participant adherence to a protocol may be related to the outcome. Effectiveness of a therapy is not simply determined by its pure biological effect, but also by the physician’s ability to administer, or patient’s ability to adhere to, the intended treatment. The true effect of a treatment is a combination of these factors. Following the ITT principle allows for an unbiased estimate of the effect of selecting one treatment over another.\nPoor treatment adherence may result in lower estimates of treatment efficacy and a loss of study power, however, these estimates are clinically relevant because real-world effectiveness is limited by the ability of patients and clinicians to adhere to a treatment.",
    "crumbs": [
      "Clinical Trials",
      "Other Considerators"
    ]
  },
  {
    "objectID": "resources/rct_other.html#alternatives-to-itt",
    "href": "resources/rct_other.html#alternatives-to-itt",
    "title": "Clinical Trials 3: Other Considerations",
    "section": "Alternatives to ITT",
    "text": "Alternatives to ITT\nPer protocol analysis: includes only study participants who completed the trial without any major deviations from the study protocol (specific definition varies between studies).\nModified ITT: deviates from the ITT approach by eliminating patients or reassigning patients to a study group other than the group to which they were randomized (specific definition varies between studies).\nBoth these methods may lead to clinically misleading results. Studies following modified ITT are more likely to find significant results than those following a strict ITT.",
    "crumbs": [
      "Clinical Trials",
      "Other Considerators"
    ]
  },
  {
    "objectID": "resources/rct_other.html#itt-caveats-to-consider",
    "href": "resources/rct_other.html#itt-caveats-to-consider",
    "title": "Clinical Trials 3: Other Considerations",
    "section": "ITT Caveats to Consider",
    "text": "ITT Caveats to Consider\nFor Non-inferiority trials both ITT and per-protocol analyses should be conducted and reported. Non-inferiority trials are designed to demonstrate that an experimental treatment is no worse than an established one. Patients randomized to the established therapy may not adhere to treatment, and fail treatment due to non-adherence. In this case, established treatment appears less efficacious, and new treatment may incorrectly appear non-inferior to established treatment.\nWhen evaluating safety; generally conducted according to treatment actually received, even though this may overestimate the burden of adverse effects likely to be seen in clinical practice.",
    "crumbs": [
      "Clinical Trials",
      "Other Considerators"
    ]
  },
  {
    "objectID": "resources/regression_linear.html",
    "href": "resources/regression_linear.html",
    "title": "Regressions 1: Linear Regression",
    "section": "",
    "text": "Topic: Introduction to linear regression, interpretation of results, assumptions, and the selection of variables.\n\nIntroduction\nLinear regression is a method of describing the relationship between a continuous outcome variable (Y) and one or more ‘predictor’ variable(s) (X) that can be binary, categorical, or continuous. Other forms of regression are used when the outcome is binary (logistic regression), categorical (multinomial regression), ordinal (ordinal regression), count data (Poisson regression), or time-to-event data (Cox Models).\n\n\nHow is it Calculated, and What Do Those Numbers Mean?\nThe figure below shows a scatter plot of two continuous variables (X and Y). We can describe the relationship between X and Y by drawing a straight line through the data points. The data points represent the observed values, whereas the line represents the predicted values; the difference between these two is called the “error” or a “residual”. The line drawn is as close as possible to the data points, specifically, the line of best fit is the one that has the smallest value for the sum of all the “errors” or “residuals”.\n\nThe line may be described by the equation:\n\\[ Y = (intercept)+(slope)(X) = β_0 + (β_1)(X) \\]\nThe intercept (β0) is the estimated Y when X = 0.\nThe slope (β1) is the estimated change in Y for a one-unit increase in X.\nWith this equation, we can estimate the value of Y for any given value of X.\nThe value of β0 and β1 are calculated and are of key interest when conducting a regression. The null-hypothesis is that the regression coefficients (i.e., β0 and β1) equal to 0, that is, the p-values associated with β0 and β1 indicate whether they are different from 0. If the line has a slope of zero (i.e., a flat horizontal line; β1 = 0), X and Y are not associated with each other; the expected value of Y will be the same regardless of the value of X.\nWhen there are two predictors (X1 and X2), the regression equation becomes:\n\\[ Y = β_0 + (β_1)(X_1) + (β_2)(X_2) \\]\nβ0 is the estimate of Y when X1=0 and X2=0.\nβ1 = expected change in Y for a one unit increase in X1 and all other variables (e.g. X2) stay the same.\nβ2 = expected change in Y for a one unit increase in X2 and all other variables (e.g. X1) stay the same.\nβ values represent the independent effect of the predictor on the outcome ‘controlling for’, ‘adjusted for’, or ‘holding constant’ all other variables.\nThis model can be expanded to include many predictors:\n\\[ Y = β_0 + (β_1)(X_1) + (β_2)(X_2) + (β_3)(X_3) +... + (β_n)(X_n)\\]\n\n\nAssumptions\n\nLinearity – relationship between the outcome (Y) and the covariates (X) is linear\nIndependence – observations/participants are independent of each other\nNormality – the residuals (not the outcome) are normally distributed\nHomogeneity of variance – the residuals have a constant variance across the levels of X (that is, the variability around the regression line is constant/similar throughout the regression line).\n\nAdditionally, you should avoid including covariates that are highly correlated in the same regression model (this is because it becomes much harder to identify their independent effects; this issue is called multicollinearity). Outliers may also be a concern and may skew results – observations with large residuals may need to be removed or a different model needs to be used.\nNote that there are no assumptions about the distribution of the covariates (X).\n\n\nCategorical Predictors\nThe interpretations discussed above expand to binary covariates, (e.g., variables with 2 categories, such as male vs. female). A linear regression with one binary covariate is equivalent to an independent samples t-test. If the variable is coded with a 0 and 1 (e.g., 0 = female, 1 = male), then:\n\nβ0 = estimate of Y when X = 0; i.e. the mean of the group coded 0. In our example, if β0 = 10.0, the mean score of females is 10.0.\nβ1 = estimated change of Y when there is a 1 unit increase in X; i.e. the difference in the mean outcome of the two groups. In our example, if β1 = 5.0, then mean score of males is 5.0 points higher than females. Since mean score of females is 10.0, the mean score of males is 15.0.\n\nIf the predictor has more than 2 categories, one of the categories is set as the ‘reference’ category, and other categories are compared against it, similar to above. The reference group is usually the largest group or most clinically relevant.\n\n\nSelection of Variables to Enter in the Model\n\nA larger sample size is required when multiple predictors are added to the model\nPrior knowledge from the scientific literature is the most important rationale. Which variables are known or thought to affect the outcome you are studying?\nDo not remove variables just because they are not significant (p &gt;.05). A p&gt;.05 is not a sign that the variables do nothing, it just means that the effects of those variables could not be detected from the sample. Leaving in not-significant variables ensures that your confidence intervals and p-values have the correct interpretation, and they are the most faithful estimates you can make\nAvoid including variables which are largely homogenous between participants. For example, if you are studying 100 patients, and only 3 of them smoke, the effects of smoking may not be estimated very well due to the small sample of those participants\nAutomated variable selection methods (backward/forward selection) provide biased results and should be avoided; they produce more extreme regression coefficients, and incorrect confidence intervals and p-values. These issues are outlined in Regression Modeling Strategies (Harrell, 2015), section 4.3, and also summarised here.\n\n\n\nComparing and Centering Regression Coefficients\nIn general, it is not possible to compare regression coefficients directly. This is because they describe the effects of a one-unit change in a variable (X), therefore, the magnitude of the regression coefficient is dependent on the units of the covariate.\nTo compare regression coefficients, they must be on the same scale. If the variables are in different scales, standardized regression coefficients (which range from -1 to +1) can be calculated/used. You can also express the effect of a change in one unit of predictor X2 as the number of units of predictor X1 giving the same effect – this is simply the ratio of the two regression coefficients: β2 / β1. For example, a ‘one hour of physical activity per week has the same effect as a difference of 2 years of age’.\n\n\nCentering Covariates\nβ0 is the value of Y when all predictors equal zero; this value may not be meaningful (e.g. estimated running speed when blood pressure is equal to 0 is not a meaningful number). In such cases, you can redefine the 0 point to make β0 meaningful, if that is of interest to you. Can do so by ‘centering’ the covariate(s); that is, subtract a constant from every value of a variable. If that constant is the sample mean, the new variable will have a mean of 0. The intercept (β0) can be interpreted as the estimated Y for the ‘average participant’. Aadding or subtracting a constant from covariates (X1, X2, etc.) will change the value of β0 but not the other regression coefficients (β1, β2 , etc.). If variables are centered, this should be made clear in the publication.\n\n\nReferences and Further Readings\nHarrell F. Regression Modelling Strategies With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis. Springer. 2015\nWerner V. Regression models as a tool in medical research. NY: Taylor & Francis Inc. 2012.",
    "crumbs": [
      "Regressions",
      "Linear Regression"
    ]
  },
  {
    "objectID": "resources/regression_multilevel.html",
    "href": "resources/regression_multilevel.html",
    "title": "Regressions 4: Multilevel (Mixed) Models",
    "section": "",
    "text": "Topic: What are multilevel models, when they should be used, and sample size considerations.\n\nIntroduction\nMultilevel models are needed to analyze data that has a hierarchical or clustered structure, such as patients treated by the same clinic, or drug levels in the same patient at multiple times. Multi-level models might also be called, mixed models, mixed-effects models, random-effects models, hierarchical models, or split-plot designs.\n\n\nWhen Are Multilevel Models Used?\nA common assumption of ‘standard’ statistical methods (e.g. t-tests, ANOVAs, regressions) is that observations (e.g. patients) are independent of each other. This assumption is violated when observations (e.g. patients) have a ‘hierarchy’, ‘clustered’, or ‘nested’ structure (as shown in the figure below) because the observations are correlated. For example, the figure below shows a ‘three-level’ data structure, whereby patients are nested within clinics, and clinics are nested within regions. Patients treated in the same clinic may be more alike with each other compared to patients seen in other clinics and are therefore positively correlated. Likewise, clinics in the same region may be more alike compared to clinics in different regions.\n\nMultilevel data structures also arise in longitudinal studies where multiple observations of individuals are made over time (as shown in the figure below). The observations from the same individual are more alike than observations from another patient, and are therefore correlated.\n\n\n\nWhat are Multilevel Models?\nWhen working with multilevel data, the existence of data hierarchies must be taken into account in the analysis; this is accomplished by using multilevel models. When data is correlated, using standard statistical methods (e.g. t-tests, ANOVAs, regressions) is not appropriate and will lead to an inappropriate estimates of standard errors, which in turn will lead to errors in statistical inference, such as p-values smaller than they really should be. The magnitude of the bias will be associated with how similar the observations are within a given cluster, this is described by the ‘design effect’ (explained below). An additional problem with ignoring the multilevel structure of the data is that we may miss important relationships involving each level in the data. For example, by not including information about the hospital we may miss important variables at the hospital level that help to explain outcomes at the patient level.\nMultilevel modelling can be conducted using R (through the lme4 or nlme packages), SAS (using proc mixed or glimmix), STATA (using the mixed or melogit commands) and SPSS (using the MIXED command). These models are quite complex and consultation with a statistician is strongly recommended.\n\n\nSample Size Considerations\nSpecial sample size formulas and computer programs are available for hierarchical data structures. The STATA clsampsi command may be helpful, though working with a statistician is advisable. Simulations for sample size estimates may also be needed.\nThe statistical power when working with clustered data may be substantially lower compared to a similarly-sized non-clustered data; that is, clustering makes it harder to detect differences. It is harder to detect differences when the ‘design effect’ is higher.\nDesign Effect = 1 + \\(\\rho\\) (m - 1)\nm = average cluster size (e.g. group size),\n\\(\\rho\\) = intra-cluster correlation (ICC); i.e. the correlation among participants within a cluster, or the proportion of overall variation in the outcome that can be attributable to clusters.\nThe design effect is small when the group size and ICC is small. Generally, increasing the number of clusters offers a greater increase in power than increasing the number of individuals per cluster. The existing literature on your target population and intervention should be used to estimate your ICC. The ICC tends to be larger for knowledge and attitudes, smaller for behaviors, and even smaller for physiologic measures. As a very general guide, for health-related outcomes the ICC values may be (Murray 2016):\n- 0.00 - 0.05 for large aggregates (such as hospitals, schools, worksites) - 0.05 - 0.25 for small aggregates (such as departments, classrooms) - 0.25 - 0.75 for very small aggregates (such as families, spouse pairs)\n\n\nReferences and Further Readings\nField A (2017). Discovering statistics using IBM SPSS statistics (5th edition). Sage.\nFinch WH, Bolin JE, Kelley K. (2019). Multilevel modeling using R (2nd ed). Crc Press.\nWest BT, Welch KB, Galecki AT (2014). Linear mixed models: a practical guide using statistical software (2nd ed). Crc Press.\nMurray DM. Pragmatic and Group-Randomized Trials in Public Health and Medicine. National Institutes of Health. 2016. https://prevention.nih.gov/grt",
    "crumbs": [
      "Regressions",
      "Multilevel Models"
    ]
  },
  {
    "objectID": "resources/research_proposal.html",
    "href": "resources/research_proposal.html",
    "title": "Developing a Research Proposal",
    "section": "",
    "text": "Topic: Review of how research proposal should be structured, primarily focusing on the objectives/aims and analyses plan sections.",
    "crumbs": [
      "Getting Started",
      "Research Proposal"
    ]
  },
  {
    "objectID": "resources/research_proposal.html#purpose-of-research-proposal",
    "href": "resources/research_proposal.html#purpose-of-research-proposal",
    "title": "Developing a Research Proposal",
    "section": "Purpose of Research Proposal",
    "text": "Purpose of Research Proposal\nThe goal of the grant proposal is to present a coherent, and carefully thought-out plan for a project that will address an important need that aligns with the funding agency’s priorities. The proposal will be evaluated by scientific reviewers who should gain a clear understanding of the importance of the project, your plan for addressing the problem, and why you/your team are best equipped to successfully undertake the project.\nIt is important to remember that the reviewer’s specialty may differ from that of the research topic, and that reviewers will not fund a study they do not understand. Therefore, the research proposal should be understandable by a general scientific audience, and you should aim to make things as simple, explicit, and concrete as possible. The proposal should also be highly readable. Don’t make reviewers work to understand your project.\nConsider the following general points to improve clarity and readability:\n\nLeave nothing open to interpretation. Be direct and explicit in labeling the purpose of a sentence or section.\n\nExamples: ‘This project is innovative because…’;\n\n‘The long-term goal of this project is…’\n‘We are a multidisciplinary team spanning cardiologists, pathologists, epidemiologists and statisticians, with the expertise to undertake the proposed research because…’\n\n\nUse bolded, underlined, or italicized text (in moderation) to highlight key phrases to make them easy to find. Phases such as “long-term goal”, “objective”, “specific aims”, “innovative”.\nBe mindful of the visual appearance of the proposal and ensure that it is not overcrowded. White space and page or section breaks are important to consider.\nDon’t use a lot of jargon or abbreviations (especially non-standard abbreviations); it is cognitive taxing to keep track of jargon or multiple abbreviations. Consider boding the first instance of an abbreviation to make it easier for reviewers to find and refer back to.\nAvoid using clichés (e.g. state-of-the-art equipment) and colloquialisms - assume reviewers may not be primarily English speaking or from Canada.\n\nAs much as possible use the language of the agency guidelines, where applicable, to reinforce how your project fits with their funding priorities. If the agency is calling for innovative projects describe your project as “innovative”, do not leave it to the reviewer to assume its innovative based on your scientific description of your project. Again, don’t make reviewers work for it.",
    "crumbs": [
      "Getting Started",
      "Research Proposal"
    ]
  },
  {
    "objectID": "resources/research_proposal.html#how-should-the-proposal-be-structured",
    "href": "resources/research_proposal.html#how-should-the-proposal-be-structured",
    "title": "Developing a Research Proposal",
    "section": "How Should the Proposal be Structured?",
    "text": "How Should the Proposal be Structured?\nFirst and foremost, always follow the guidelines and never exceed the space allotted.\nThough writing styles and requirements from different agencies vary, an approach that is often recommended is to begin your grant proposal with a summary and the specific aims (the focus of this document), followed by a more detailed background section, the experimental design, measures, statistical analyses, and limitations and alternative plans.\nThe summary and specific aims section should serve as an abbreviated summary of the entire proposal and provide reviewers with a guide of what to expect from the rest of your proposal. The language and terminology used in the summary and specific aims sections should be used consistently throughout the proposal to maintain consistency. The specific aims section is the most important part of the proposal because all subsequent sections should always link back and support the specific aims. The structure of this section can follow a specific formula (described below).",
    "crumbs": [
      "Getting Started",
      "Research Proposal"
    ]
  },
  {
    "objectID": "resources/research_proposal.html#summary-and-specific-aims-section",
    "href": "resources/research_proposal.html#summary-and-specific-aims-section",
    "title": "Developing a Research Proposal",
    "section": "Summary and Specific Aims Section",
    "text": "Summary and Specific Aims Section\nRequirements for each proposal will differ, but the section below provides a concrete example of how this section can be organized in four paragraphs:\n1) Introduction The goal of the introductory paragraph is to ensure reviewers understand: a) the current knowledge in the field, b) the gap that constitutes an important problem, and c) the importance of address this gap. Consider using the following structure:\n\nAttention grabber/the Hook: Begin with an attention-grabbing sentence to establish the relevance of your proposal to human health. Be careful to not state information that would be intrinsically obvious to the reviewers. The sentence should compel the reader to read on.\n\nExample: Although the majority of children with epilepsy achieve seizure control in the long-term, the cognitive, psychiatric, and psychosocial problems that are pervasive among 80% of children continue to persist.\n\nWhat is known: This part aims to ensure that all reviewers have the required background knowledge to understand the problem, and sets up the knowledge gap or the unmet need that will be addressed.\nGap in knowledge: Clearly state the gap that needs to be addressed and why it is important.\n\nExamples: ‘What is not known is…’; ‘Thus there is an urgent need for …’; ‘This lack of knowledge represents an important problem because…’\n\nThe Critical Need: This is the knowledge, technique, or treatment your proposal will develop; the reason your proposal should be funded. Emphasize the significance of the problem and that your research is the next logical step. You should state why your project is a timely investment. Is there any urgency to solving this problem sooner rather than later? What’s the impact of not addressing this issue?\n\n2) Goals / Objectives The goal of the second paragraph is to introduce the solution to the identified gap/need. Include the following in this section:\n\nLong-term Goal: The overarching goal and continuum of research that you will pursue over the course of multiple grants. This goal should be broad enough to encompass the gap or need identified previously.\n\nExample: ‘Our long-term goal is to …’\n\n* Objective: Defines the purpose of the current grant application - what it seeks to accomplish, which should be to fill the gap/need identified previously. This should be focused on the product of the research (not the process) and should therefore be to either fill in the gap or meet a need. The objective should have a defined end point.\n\nIt is not appropriate to state “to study X”. This is focused on the process (not the product) and there is no defined end point (i.e. when have you ‘studied’ a topic enough?)\nExample: ‘The overall objective of this proposal, which is the next step toward attaining our long-term goal, is to .’\n\nCentral Hypothesis: This should link to the Objective, should be testable, and should provide a focus (i.e. it should give direction to the research; it should serve to set up the specific aims, discussed below). Briefly explain the rationale for the hypothesis in this section, and if needed, refer to a more detailed explanation elsewhere in the proposal. Avoid vague hypotheses because it will be unclear what you expect to determine with the proposed research.\n\nExample: ‘Our central hypothesis is that…’\n\n\n3) The Specific Aims The goal of the third paragraph is to describe the aims that will test the central hypotheses. There should be complete alignment between the Specific Aims and Central Hypothesis.\n\nBegin this section with an explicit sentence such as “We plan to test our central hypothesis and accomplish the overall objective of this application by pursuing the following specific aims:”\nThe aims should be related but should not be dependent on each other (e.g., Aim 2 should not rely on the success of Aim 1).\nEach Aim should be in a separate line, numbered and indented, to improve readability.\n\n4) Summary / Impact The goal of the fourth paragraph is to create a firm, broad base to support the proposal, and can include the following information.\n\nInnovation: what makes your project innovative?\nExpected outcomes: Discuss the expected outcomes and why they are important. If this was discussed in the specific aims it may not need to be repeated here.\nStudy Team: End this paragraph by indicating why you, your team, and your research environment are best positioned to accomplish this research. Keep it brief but emphasize that your team has the scope and breadth of experience necessary to successfully conduct the research. \\\nImpact: Generalize the positive impacts that are anticipated from the expected outcomes. If applicable, this section should also speak to a) the jurisdictional context of the project and the impact/generalizability to other jurisdictions, and b) the potential cost-savings to the healthcare system, or other patient-, systems-, or societal-level benefits of the work. Addressing these points demonstrates you understand where your work is situated in the wider research setting.\n\nAgain, each proposal will be unique, and a different organization may need to be utilized. Nonetheless, consider the information outlined above and consider including the elements discussed in your grant proposal.",
    "crumbs": [
      "Getting Started",
      "Research Proposal"
    ]
  },
  {
    "objectID": "resources/research_proposal.html#example-of-the-objectivesspecific-aims",
    "href": "resources/research_proposal.html#example-of-the-objectivesspecific-aims",
    "title": "Developing a Research Proposal",
    "section": "Example of the Objectives/Specific Aims",
    "text": "Example of the Objectives/Specific Aims\nOur long-term goal is to improve the quality of life of children with epilepsy. The objective of this pilot trial is to evaluate the feasibility of utilizing drug A and B as an intervention for children with epilepsy. Our central hypothesis is that drug A and B will be successfully implemented, and that drug A will be more effective at improving seizure frequency and health-related quality of life, relative to drug B for children with epilepsy. We plan to test our central hypothesis and accomplish the overall goal of this trial by pursuing the following specific aims:\nPrimary Aim: 1. To assess the feasibility of successfully implementing drug A as an intervention for children with epilepsy. Specifically, we will evaluate a) study procedures (e.g. recruitment, attrition, time to complete study procedures), b) participant adherence to treatment\nThis information will be essential in preparing for a subsequent multi-centered trial across Canada. Feasibility outcomes will be evaluated throughout the course of the study and the specific outcomes collected and evaluated are presented in Section X.\nSecondary aims are to obtain preliminary data regarding the impact of drug A and B on: 1. Children’s frequency of seizures at 6-months follow-up. 2. Children’s health-related quality of life (HRQOL) at 6-months follow-up.\nAll secondary outcomes (efficacy outcomes) will be evaluated two weeks before the commencement of the drug and six months after commencement. The specific outcomes that will be collected and evaluated are presented in Section X.",
    "crumbs": [
      "Getting Started",
      "Research Proposal"
    ]
  },
  {
    "objectID": "resources/research_proposal.html#purpose-of-the-analysis-plan",
    "href": "resources/research_proposal.html#purpose-of-the-analysis-plan",
    "title": "Developing a Research Proposal",
    "section": "Purpose of the Analysis Plan",
    "text": "Purpose of the Analysis Plan\nA detailed, clearly written statistical analysis plan is an essential part of any competitive research proposal and serves two key purposes, outlined below:\n1) Ensures Data Collected Can Answer the Question Proposed If the specific aims, study design and structure of the data (e.g. how the constructs of interest are operationalized and recorded) are not aligned to optimally support the analysis plan, the investigator may not be able to answer the research question of interest. Potential flaws in the study design or proposed data structure are easier to identify once the investigator have carefully developed an analysis plan and carefully considered what the data file and the results will look like.\nIt is not uncommon for a statistician to be first consulted when the data needs to be analyzed, only to find that the study deign and/or data collected cannot does not align with the research question and the analyses required. Therefore, it is strongly recommended that a statistician be involved in all aspects of the study, from conceptualization to knowledge translation. Challenges are best identified and addressed in the design stage of the study, rather than trying to solve problems at the analysis stage. Addressing a mismatch of what was intended versus what is possible with the data collected, is much more complicated (or not possible all together) at the analysis stage, once data has been collected.\nLastly, data collection is expensive, and one needs to know the value of each data point collected, and how it will be utilized to keep the burden on patients low, and to conduct the project efficiently.\n2) Demonstrates a Clear Plan to Reviewers The analyses plan section also highlights to reviewers that a coherent, and carefully thought-out research plan has been developed. A vague analysis plan will suggest to reviewers that there is no actual plan, connoting to reviewers that the applicant is proposing the “just trust me” approach, which may suggest some risk to the reviewers/agency and erode their confidence in timely project deliverables. Leaving the plan for analyzing the data until later is counter-intuitive since the value of any proposed study/experiment hinges on the results arising from proper analysis and interpretation.",
    "crumbs": [
      "Getting Started",
      "Research Proposal"
    ]
  },
  {
    "objectID": "resources/research_proposal.html#getting-started-specific-aims-and-methods",
    "href": "resources/research_proposal.html#getting-started-specific-aims-and-methods",
    "title": "Developing a Research Proposal",
    "section": "Getting Started: Specific Aims and Methods",
    "text": "Getting Started: Specific Aims and Methods\nBefore starting on the analysis plan, the specific aims, methods, and operationalization of variables should be developed and aligned, as described below:\n\nEnsure that each section of your proposal is inherently connected and builds on previous sections. Each specific aim should be detailed enough to have a clear method of being analyzed. Additionally, all subsequent sections, such as the methods, the outcomes and variables, and the analyses plans, should always link back to the specific aims.\n\nOne way to achieve this may be to label each specific aim (e.g. 1, 2a, 2b, 3), and consistently refer to these labels throughout the analyses plan, e.g. “To evaluate Aim 1, ….”\n\nIn the methods section, ensure that the outcome, exposure / predictor variable, and all co-variates evaluating theoretical constructs of interest are explicitly operationalized – i.e. clearly defined and described in terms of the data type and scale of measurement. Always think about what the data will look like in the spreadsheet/database and what these variables will be.\n\nFor example, you may be interested in ‘adverse events’, but how will this theoretical construct be measured, what will the data look like? This may be operationalized as a binary variable (e.g. yes vs. no) indicating whether the patient had at least one adverse event within X months after a procedure. Alternatively, it may be operationalized as a count variable indicating the number of adverse events that occurred within X months after a procedure.\n\nTheoretical constructs may be operationalized in many ways, so you must be explicit in how you will define and measure them. Remember to specify the time point that variables will be collected. Determining the operationalization of the constructs is the first step to generating the analysis plan.\n\nThe type of data collected and how variables are operationalized will determine the type of analyses your able to perform and will therefore dictate the type of research questions that can be answered.",
    "crumbs": [
      "Getting Started",
      "Research Proposal"
    ]
  },
  {
    "objectID": "resources/research_proposal.html#writing-the-analysis-plan",
    "href": "resources/research_proposal.html#writing-the-analysis-plan",
    "title": "Developing a Research Proposal",
    "section": "Writing the Analysis Plan",
    "text": "Writing the Analysis Plan\nEnsure that all analyses directly link to your specific aims and hypotheses. Consider the following points to ensure that the analysis plan has been described adequately and in unambiguous terms:\n\nReviewers will check that the proposed analyses are appropriate and will adequately account for the study design, data structure (e.g. hierarchy, clustering, matching, paired data) and scale of measurement (e.g. binary, nominal, ordinal, continuous).\nReviewers will also check that the assumptions of the proposed methods hold, and you should indicate the planned analyses if assumptions do not hold. This exemplifies that the plan for handling the data is well thought out and you have a plan for everything.\n\nFor example, you could indicate: We plan to do a Poisson regression. The data will be checked for over dispersion via a deviance goodness of fit test. In the case where dispersion is present, a negative binomial model will be used.\n\nExplain statistical concepts in a clear, concise language that is accessible to:\n\n-   Non-statisticians -- explaining the big picture and why more than a t-test is required\n\n-   Statisticians -- using statistical terminology and specific statistical techniques\n\nUtilizing statistical terminology and naming the specific statistical methods is appropriate and helpful. It will show that you and your team are knowledgeable and capable of doing the analyses.\n\nReviewers should feel reassured that you have thought in some detail about how the data will be collected, measured and analyzed to address the study aims. However, it is important that you understand the terminology and use it appropriately; otherwise reviewer will lose confidence in your team’s ability to successfully carry out the project.\n\nImportant confounding factors should be listed, and the method of adjustment specified.\n\nIn planning the study and the analysis, it may be helpful to create mock tables and figures for the data you wish to ultimately present and work backwards to ensure that the data collection and analyses plan align with your goal.",
    "crumbs": [
      "Getting Started",
      "Research Proposal"
    ]
  },
  {
    "objectID": "resources/research_proposal.html#examples-of-analysis-plans",
    "href": "resources/research_proposal.html#examples-of-analysis-plans",
    "title": "Developing a Research Proposal",
    "section": "Examples of Analysis Plans",
    "text": "Examples of Analysis Plans\n\nPatient characteristics will be summarized using mean and standard deviation (for continuous variables) or frequency and proportions (for categorical variables). For the primary outcome (systolic blood pressure 90 days after intervention), multiple linear regression will be used to compare the two intervention groups (drug A vs. drug B), while adjusting for known confounders: patients’ age, sex, and body mass index at baseline. With respect to secondary and exploratory outcomes, the same methodology will be used for continuous variables, while binary outcomes will be evaluated using multivariable logistic regression adjusting for patients’ age, sex, and body mass index at baseline. Two-tailed tests will be used, and the level of significance will be set to 0.05.\nPatient characteristics will be summarized using mean and standard deviation (for continuous variables) or frequency and proportions (for categorical variables). All patients enrolled in the study will be analyzed based on their randomization group, following the intention-to-treat principle. The primary end point, ability to walk unassisted for 10 meters at 30 days post intervention (yes vs. no), will be compared between the two groups (treatment vs. control) using simple logistic regression. Secondary outcomes of the two groups will be compared using simple linear regression (for continuous variables; e.g. body mass index, lean muscle mass), logistic regression (for binary outcomes; e.g. adverse event), Poisson regression (for count data, e.g. length of hospital stay), and log rank test (for time to event data; e.g. patient survival). For variables evaluated before and after randomization (e.g. lean muscle mass), the score at follow-up will be entered as the dependent variable, and treatment group and baseline score will be entered as a covariates. Two-tailed tests will be used, and the level of significance will be set to 0.05.\nPatient characteristics will be summarized using mean and standard deviation (for continuous variables) or frequency and proportions (for categorical variables). Poisson regression with robust error variance (Zou, 2004) will be used to estimate the relative risk (RR) of sepsis among patients with diabetes compared to non-diabetic patients (Aim 1). Unadjusted estimates will be evaluated, as well as RR adjusted for age, sex, socio-economic status, comorbidities (COPD, cancer, congestive heart failure, coronary artery disease). Among patients with sepsis, we will estimate the odds of organ failure and mortality among those with and without diabetes (Aim 2) using unadjusted logistic regression. Multivariable logistic regression will also be used to adjust for age, sex, and comorbidities (COPD, cancer, congestive heart failure, coronary artery disease). Two-tailed tests will be used and the level of significance will be set to 0.05.\nTo evaluate study feasibility (Research Question 1), descriptive statistics will be used to determine the 1) number of participants screened and enrolled per month, 2) proportion of screened participants eligible who enroll, 3) reasons for non-participation, 4) retention rate in treatment and waitlist control condition, 5) missing data on questionnaires, 6) time to complete questionnaires, and 7) participant adherence (proportion of missed doses). To evaluate the impact of the intervention on the frequency of emergency department visits over the next 12 months (Research Question 2), the two study groups will be compared using Poisson regression (or zero-inflated negative binomial regression if the outcome variable consists of a large number of zeros). To evaluate the impact of the intervention on quality of life and self-management skills (Research Question 3; all are continuous variables), the baseline and each follow-up for the intervention and control group will be compared using linear mixed models. Mixed models have the advantage of utilizing all available data without discarding participants with missing follow-up measures. We will also evaluate whether the proportion of participants who show a clinically significant improvement on quality of life (improved scores by &gt;10 points) at 12 months is significantly different between the treatment and control group using simple logistic regressions. All analyses will follow the intention-to-treat principle, using two-tailed tests, and the level of significance set to 0.05.",
    "crumbs": [
      "Getting Started",
      "Research Proposal"
    ]
  },
  {
    "objectID": "resources/stat_clin_significance.html",
    "href": "resources/stat_clin_significance.html",
    "title": "Statistical vs. Clinical Significance",
    "section": "",
    "text": "Topic: Review of statistical significance, clinical relevance, and confidence intervals.\nStatistics plays two main roles: 1) measure variability in the data in an effort to assess the role of chance, and 2) estimate effects after correcting for biases such as confounding. Here we focus on the former.\n\nStatistical Significance (the p -value)\nThe p-value is the probability of getting the result obtained (or more extreme results) if the null hypothesis were true. Null hypothesis is a statement suggesting that nothing interesting is going on (e.g. no difference between two groups).\nA p-value of .04 means that, if the null hypothesis is true (i.e. groups are equivalent), there is a 4% chance of seeing the observed data or data even more extreme. It does not mean that the probability of the groups being equivalent is 4%, nor does it mean that the probability that the groups differ is 96%.\nIf the p-value is less than 0.05, the observed results are unlikely if the null hypothesis were true. You can conclude statistically significant results; i.e. null hypothesis is not true; i.e. groups are different.\nIf the p-value is high (\\(\\geq\\) 0.05), you cannot conclude that there is no difference between the groups, or that the intervention doesn’t improve outcome, etc. You can only conclude that your experience did not prove or find a difference. Failure to prove a treatment is effective is not the same as proving it ineffective.\nImportantly, p-values are dependent on sample size and provide virtually no information about the strength of the evidence supporting or refuting the null hypothesis.\n\n\nClinical Significance\nIf a study is very large, the results may be statistically significant, but the difference between the two groups may be too small to be of any clinical interest. Conversely, a large differences may not be statistically significant if the study sample size was small (or “under powered”), however the large difference may be of clinical relevance and needs further testing from future studies. Therefore, do not overly focus on the p-value. If you have a small sample, a descriptive study (without any statistical tests or p-values) can provide valuable information and can be published.\nMagnitude of improvement is of primary interest, not the p-value or statistical significance. Statistics cannot answer this question; requires clinical judgment and consideration for the magnitude of benefit, side effects, costs, and patient preferences.\n\n\nConfidence Intervals (CI)\nConfidence Intervals (CI) express the uncertainty associated with the results, typically 95% CI\nAs an example, consider the following results related to blood pressure: mean reduction is 7mm Hg, p =.03, and 95% CI is 4 to 10. Instead of focusing on significance (p-value) indicating the probability of seeing the observed (or more extreme) data if the null hypothesis were true, CIs convey more relevant information. CIs indicate the best guess for the size of the effect in the population, 95% of the time. In this case, the estimated mean reduction in blood pressure is between 4 to 10 mm Hg.\nCIs that exclude the null value (0 for differences, 1 for ratios), are statistically significant at p&lt;.05\nReporting a CI shifts the focus from “is this result statistically significant?” to “are there clinically important values in this range, and is the range narrow enough for comfort?\n\n\nReferences and Further Readings\nGreenland, S., Senn S.J., Rothman, K.J., et al. (2016). Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. European Journal of Epidemiology, 31, 337-50.\nHarris M, Taylor G. Medical statistics made easy. Banbury, England: Scion Publishing; 2014.",
    "crumbs": [
      "Other Topics",
      "Statistical vs Clicical Significance"
    ]
  },
  {
    "objectID": "resources/study_case_reports.html",
    "href": "resources/study_case_reports.html",
    "title": "Study Design 4: Case Reports",
    "section": "",
    "text": "Topic: Description of pilot studies and how pilot studies should be designed.\n\nIntroduction\nA case report is a research design that provides an in-depth description and analysis of a ‘case’. Case reports can be very diverse and encompass an individual (e.g. a patient), a social group, institutions (e.g. a hospital), or an event.\nCase reports play an important role in evidence generation, in clinical practice, and in raising awareness of understudied or poorly understood phenomena. They can be prospective or retrospective and are often used to investigate “why” or “how” questions. There are three types of case study designs:\n\nExplanatory - investigates cause-and-effect relationships\nExploratory - identifies hypothesis or research questions, or assesses the practicability of research protocols\nDescriptive - provides an in depth description of a case\n\nReporting guidelines have been developed by the Equator Network and should be followed (the CARE guidelines): http://www.equator-network.org/reporting-guidelines/care/\n\n\nGetting Started\n\nIdentify the interesting aspects of the case and learning points to highlight.\nReview the literature to determine what is known and refine the objectives of the case report.\nThe research objective/hypotheses should be formulated prior to data collection. This will help with the identification and collection of supporting evidence.\nCritically evaluate the quality of the available data and identify potential biases or potential errors.\nA number of journals provide guidance documents on how to draft a case report (see Further Readings below).\n\n\n\nEthics Approval\nObtaining patient’s consent to publish the case report is very important, and it may also be a journal requirement. In reporting results, care should be taken to maintain the confidentiality of the case.\n\n\nData Collection\nMethods typically used include interviews, observation, and archived records. Before data collection begins, authors should have a method/protocol in place to accurately collect, store, organize, and access the data while maintaining patient confidentiality. Whenever possible, data should always be acquired from multiple sources, increasing the credibility of available evidence.\n\n\nAnalysis and Reporting\nThere are no “recipes” to help guide analyses, which will largely depend on the case, the research question, and the researchers’ ability to critically evaluate the evidence. The report should demonstrate critical thinking and logical reasoning and provide a clear and compelling story, highlighting the main learning points. Why a case study design is the preferred method for the research question should also be discussed. Lastly, consider sharing the results and interpretation with the case(s) to evaluate the accuracy of the data.\nCaution should be taken in generalizing results of case reports because they have the potential to allow for over- or mis-interpretation.\n\n\nReferences and Further Readings\nBMJ Case Reports. Instructions for Authors. https://casereports.bmj.com/pages/authors/\nHancock D R & Algozzine R (2006). Doing case study research: A practical guide for beginning researchers. New York: Teachers College Press.\nJackevicius C. The Value of Case Reports. The Canadian journal of hospital pharmacy. 2018 Nov;71(6):345. Stokes V, Fertleman C. Writing a case report in 10 steps. BMJ. 2015 May 27;350: h2693.",
    "crumbs": [
      " Other Study Designs",
      "Case Reports"
    ]
  },
  {
    "objectID": "resources/study_pilot_studies.html",
    "href": "resources/study_pilot_studies.html",
    "title": "Study Design 3: Pilot Studies",
    "section": "",
    "text": "Topic: Description of pilot studies and how pilot studies should be designed.\n\nWhat is a Pilot Study?\nThe objective of the study will determine whether or not it is a pilot study. Pilot studies aim to test the study methods and procedures to be used subsequently at a larger scale, and/or to search for possible effects and associations that may be worth evaluating in a subsequent larger study. They are designed to test the performance and capability of study designs, measures, procedures, recruitment criteria, and operational strategies that are under consideration for use in a subsequent study. The intent is to guide the planning of a subsequent, often larger, investigation. Consequently, the primary objective or specific aim of pilot studies must focus on some aspect of feasibility; otherwise it is not a pilot study, by definition. The primary objective should not be to determine statistical significance. Pilot studies can be randomized or non-randomized.\nThe reasons for conducting pilot trials can be categorized as:\n\nProcess – Evaluate potential challenges in screening, recruitment, enrollment, retention rates, etc.\nResources – Evaluate potential time and budget problems that may occur during the main study, such as how long it would take to mail or fill out the surveys, whether use of certain equipment will be feasible, whether the data collection tools can be reliably completed.\nManagement – Evaluate potential human and data optimization problems, such determining capacity, do the investigators have the time to perform their tasks, will study participants overload the phone line or waiting rooms, what are the challenges at participating centers.\nScientific – evaluate treatment safety, dose levels and response, and treatment effect, variability in outcomes\n\n\n\nRecommendations for Pilot Studies\n\nThe primary objective must be to evaluate some aspect of feasibility.\n\nIn designing the study, there should be clear feasibility objective(s), clear analytic plans, and clear criteria for what will be considered a success. For example:\n\nat least 90% of patients receive the study drug within 24 hours of randomization;\nat least 90% of necessary dose adjustments will be appropriate in response to pre-defined laboratory criteria;\nat least 70% of all eligible patients can be recruited.\n\n\nDevelop a study protocol and update it throughout the course of the pilot study. This document will serve as the basis for subsequent grants and publications.\nThe sample used in the pilot may be included in the main study only if the study design has not changed and if the key features of the main study are preserved in the pilot (e.g. blinding).\nEvery effort should be made to publish pilot studies. Pilot studies are often not published because of the way the results are presented, with emphasis wrongly placed on statistical significance instead of on feasibility (which is the focus of pilot studies). Emphasize the feasibility aspects of the study.\n\nReporting of pilot trials should follow the CONSORT guidelines (Eldridge et al. 2016).\nConsider publishing in journal focused on pilot studies, such as BMC’s Pilot and Feasibility Studies journal.\n\n\n\n\nSample Size\nSample size calculations are not required for pilot studies, however pilot studies are not exempt from the need to have a clear and well-reasoned rationale for the number of participants included. The sample size should be large enough to provide useful information about the aspects of feasibility that are being evaluated. The aim of pilot studies is not to provide definitive evidence for a treatment effect; power calculations are not a valid consideration for sample size if the objective does not include any hypothesis tests.\nA confidence interval (CI) approach (focused on precision) can be used if the objective is to estimate a proportion of people with a given outcome (e.g. adherence rate). For example, if a trial would be considered successful if $$90% of patients adhere to the treatment; the smallest sample size required to have a confidence level of 95% that the adherence rate is within 5% of the desired adherence rate, will be at least 139 participants. This calculation is based on the formula below:\n\\[ n = \\dfrac{\\rho(1 - \\rho)(z^2)}{d^2} = \\dfrac{0.90(1 - 0.90)(1.96^2)}{0.05^2} = 139 \\]\nNote: for 80%, 90% or 95% CI, the z value is equal to 1.28, 1.64, or 1.96, respectively.\nYou can also use an online calculator, such as that found  here. \n\n\nInappropriate or problematic applications of the term “pilot”\n\nWhen applied to studies with little or no funding. Although pilot studies are often considered less important than other studies, they require just as much planning and methodological rigor; a study should not be called a pilot just because it has a small sample size or inadequate methodological rigor.\nWhen applied to studies with vague, poorly developed research questions and/or poor alignment of specific aims and analyses. Studies with analyses that focus on treatment efficacy may be better described as exploratory studies (pilot studies focus on feasibility outcomes).\nWhen the rationale is simply that the study precedes a more costly study. This is problematic because there is no assurance that the pilot study will provide valuable information needed to inform the successful design and execution of the subsequent study. The study should have clear feasibility objective(s) with a clear analytic plan.\n\n\n\nExample of Objectives, Sample Size and Analysis Plan\nOur long-term goal is to improve the quality of life of children with epilepsy (CWE). The objective of this pilot trial is to evaluate the feasibility of utilizing drug A and B as intervention for CWE. Our central hypothesis is that drug A and B will be successfully implemented, and that drug A will be more effective at improving CWE’s severity of seizures, relative to drug B. We plan to test our central hypothesis and accomplish the overall goal of this trial by pursuing the following specific aims:\nPrimary Aim:\n\nTo assess the feasibility of successfully implementing drug A as an intervention for CWE. Specifically, we will evaluate: a) Participant adherence to treatment b) Study procedures (e.g. recruitment, randomization, attrition, time to complete study procedures).\n\nThe main trial would be feasible if the overall adherence rate to the medication is $$80%. This information will be essential in preparing for a subsequent multi-centered trial across Canada. Feasibility outcomes will be evaluated throughout the course of the study and the specific outcomes collected and evaluated are presented in Section X.\nSecondary aims are to obtain preliminary data regarding the impact of drug A and B on:\n\nChildren’s severity of seizures at the 6-month follow-up.\n\nAll secondary outcomes (efficacy outcomes) will be evaluated two weeks before the commencement of the drug and six months after. The specific outcomes collected and evaluated are presented in Section X.\nSample Size: This trial will be considered a success if an overall adherence rate of 80% is achieved (e.g. 20% of doses are missed). A total sample size of 62 participants is required to estimate the expected proportion with 10% absolute precision and a 95% confidence interval (Thabane et al. 2010).\nAnalysis Plan: To evaluate study feasibility (Primary Aim), descriptive statistics will be used to determine the 1) participant adherence to each treatment (proportion of missed doses), 2) number of participants screened and enrolled per month, 3) proportion of screened participants eligible who enroll, 4) reasons for non-participation, 5) retention rate in treatment and waitlist control condition, 6) missing data on questionnaires, and 7) time to complete questionnaires. To evaluate the impact of the intervention on the severity of seizures (GASE score) at the 6 month follow-up (Secondary Aim), linear regression will be used to compare each groups’ scores at the 6 month follow-up, while adjusting for scores at baseline. All analyses will follow the intention-to-treat principle, using two-tailed tests.\n\n\nReferences and Further Readings\nEldridge SM, et al. CONSORT 2010 statement: extension to randomised pilot and feasibility trials. BMJ 2016; 355:i5239.\nLancaster GA, Thabane L. Guidelines for reporting non-randomised pilot and feasibility studies. Pilot and Feasibility Studies 2019; 5: 144.\nThabane L, et al. A tutorial on pilot studies: the what, why and how. BMC Medical Research Methodology 2010; 10:1.",
    "crumbs": [
      " Other Study Designs",
      "Pilot Studies"
    ]
  },
  {
    "objectID": "resources/surveys_invitation.html",
    "href": "resources/surveys_invitation.html",
    "title": "Survey Design 1: Invitation and Follow-up",
    "section": "",
    "text": "Topic: Review of empirically validated methods and strategies that can improve survey participation.\nThis document follows the recommendations of the Tailored Design Method  by D.A. Dillman (2014).\n\nIntroduction\nA grounding principle of effective survey design involves customizing and tailoring the survey and study procedures to fit the context, considering the survey population, topic, and survey mode. What works for some studies does not work for others. The aim should be to develop a hoslistic design, focusing on all aspects of the methodology, rather than focusing on only one or two features as a means of encouraging response, ignoring other aspects. Special focus should also be given to both the response rate and nonresponse error; it is not helpful to increase response rates if doing so only brings in a certain type of respondents, thereby biasing results.\nThe strategies and methods described below have been empirically shown to increase response rate and quality of reporting. Again, customize your study procedures and survey to fit your context.\n\n\nStudy Invitation\n\nBuild upon previously established relationships and specify how the survey results will be useful and why the study is important. Ask for participants’ help to provide insight into the problem.\n\nBefore sending the paper/online survey: contact individuals in person or via phone/mail, and provide them with a letter of information outlining the aims and importance of the study, and what participation in the study will involve. Allow time for them to evaluate the request and follow-up in person or with a phone call to answer any questions they may have.\n\nEstablish trust. Trust is one of the most important issues affecting response to questionnaires.\n\nAssure confidentiality and protection of data. Indicate how the information will be protected.\nUse institutional letterhead in all communications to emphasize sponsorship by a legitimate authority (e.g. the affiliated hospital and university). The better known an organization is to a potential participant, the greater the likelihood they will respond.\nProvide ways for potential participants to ask questions about the study and assess the authenticity of the survey request and ask questions about it. E.g. provide a physical address, phone number, email, website, etc.\n\nIndicating that a small number of people have an opportunity to participate can be motivational. Therefore, if possible, stress that opportunities to respond are limited (unless the study is a census, where everyone is asked) and that you request their help to solve the problem being addressed.\nDo not offer people an initial choice of survey mode (e.g. online or mailed paper questionnaire).\n\nDoing so tends to decrease final response rates, perhaps because it makes the response decision more complex, and leads to individuals delaying response.\n\nIf possible, do not deny the existence of benefits to the individual. Doing so denies the possibility and likelihood that some respondents enjoy completing surveys, providing answers to questions they find interesting, and/or contributing to research that may be helpful to others.\n\n\n\nIncentives and Follow-up\n\nSend a monetary incentive along with the study survey. This is more effective than a larger incentive given upon completion of the survey, and more effective than lotteries.\n\nAn initial incentive is very effective because of reciprocity; the researcher has given something to the potential participant, who may be more willing to complete the survey in response.\n\nPersonalize letters with the participants’ name and use different modes of contact to create synergy and encourage responses.\n\nFor example, send a mailed request for participation in an online survey and include a link to the survey and a small gift card as an incentive. Follow this request a few days later with an e-mail containing an electronic link to the web survey. Follow-up with non-responders by sending a mailed reminder and a paper questionnaire (with a pre-stamped and pre-addressed return envelope and, possibly another monetary incentive). A few days later send a final email notification.\nNote that each follow-up conveys new information and should discuss the importance of the study in different ways to spread the appeal and get participants interested in the study.\n\nConvey that others have responded. Knowing that others have completed a survey can encourage people to participate. For example, indicate “we are just waiting on a few last responses to finish the study, and would like to include yours”.\nIf possible, show the similarity of the survey request to other requests to which the person has responded. People strive to be consistent in their attitudes, beliefs, and actions. For example, when following up with the follow-up survey indicate that the participants’ response to the baseline survey was very helpful and much appreciated.\n\n\n\nDecrease the Cost of Participation\n\nBe mindful of the participant burden. Should avoid placing participants in situations where they are required to respond to long and detailed survey, with questions the respondent either does not understand or cannot answer.\nReduce the burden of length. Long surveys often lead to mid-survey terminations or increased item non response (skipped items).\nReduce complexity. E.g. ask for the range of income, as opposed to the exact income and from all sources which may require a significant amount of time and energy for participants to determine.\nMake the survey visually pleasing and informative, to help guide respondents in how to answer questions and in what order.\nAvoid subordinating language.\n\nFor example, avoid statements such as “For us to help solve the school problems in your community, it is necessary for you to complete this questionnaire.” Instead ask for their assistance in helping to solve the school problems in their community.\n\nMake it as easy as possible for participants to respond (e.g. include pre-stamped and pre-addressed return envelope for hardcopy surveys).\nBe strategic and minimize requests to obtain personal or sensitive information. When this data is required, it may best to:\n\nUse a self-administered survey to provide a sense of increased privacy.\nAsk for this data later in the survey to allow time for trust and rapport to develop.\nProvide a simple explanation for why responses to these questions are important. For example, “the next two questions will allow us to compare your health to that of other people in the study who are similar to you”.\n\n\n\n\nReferences and Further Readings\nDillman, D. A., Smyth, J. D., & Christian, L. M. (2014). Internet, phone, mail, and mixed-mode surveys: the tailored design method. John Wiley & Sons.",
    "crumbs": [
      "Survey Design",
      "Invitation and Follow-up"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Methodological and Statistical Resources",
    "section": "",
    "text": "Below are a list of resources developed to introduce trainees to a variety of methodological and statistical topics. One-on-one support is also provided, for further details click here\n\n\n\nGetting Started\n\nData Formatting\nDeveloping a Research Proposal\nSample Size Calculator\n\n\n\n\nR\n\nIntroduction to R\nIntroduction to Quarto\n\n\n\n\n\n\n\nClinical Trials\n\nStudy Design\nRandomization\nOther Considerations\n\n\n\n\nOther Study Designs\n\nCase Control\nRetrospective Chart Review\nPilot Studies\nCase Reports\nSystematic Reviews\n\n\n\n\n\n\n\nRegressions\n\nLinear Regression\nLogistic Regression\nSurvival Analysis\nMultilevel (Mixed) Models\n\n\n\n\nOther Topics\n\nStatistical vs. Clinical Significance\nWorking with Categorical Data\nConfounding\nInter-rater Reliability\n\n\n\n\n\nSurvey Design\n\nInvitation and Follow-up\nDesiging Effective Questions"
  }
]